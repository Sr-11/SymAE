{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **README**\n",
    "  \n",
    "[GVAE] H. Hosoya, “Group-based Learning of Disentangled Representations with Generalizability for Novel Contents,” in Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, Macao, China, 2019, pp. 2506–2513, doi: 10.24963/ijcai.2019/348.\n",
    "\n",
    " \n",
    "[MLVAE] D. Bouchacourt, R. Tomioka, and S. Nowozin, “Multi-Level Variational Autoencoder: Learning Disentangled Representations from Grouped Observations,” arXiv:1705.08841 [cs, stat], May 2017, Accessed: Feb. 19, 2021. [Online]. Available: http://arxiv.org/abs/1705.08841.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import python packages and initialize gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import os, sys, time, glob, io, pprint, re, shutil\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "tfk = tf.keras\n",
    "tfkl = tfk.layers\n",
    "tfkltd = tf.keras.layers.TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from absl import app, flags\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sys.version_info[0]==3:\n",
    "    sys.exit(\"Python 3 required\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs\", len(logical_gpus), \"Logical GPUs\\n\\n\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)        \n",
    "tfk.backend.clear_session()\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('num devices = %d'%strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INSTANCES = 21 # number of instances in a bag\n",
    "NUM_CLASS = 10     # mnist has 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten MNIST data 28*28 to 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### My Tmnist dataset #####\n",
    "#Tmnist = np.genfromtxt('TMNIST_Data.csv', delimiter=',', \n",
    "    #                   names=['names', 'labels'])\n",
    "df = pd.read_csv('TMNIST_Data.csv')\n",
    "Tmnist_labels = df.to_numpy()[:,1]\n",
    "Tmnist_labels = np.array(Tmnist_labels, dtype='float32')\n",
    "Tmnist_images = df.to_numpy()[:,2:]\n",
    "Tmnist_images = np.array(Tmnist_images, dtype='float32')\n",
    "Tmnist_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trn_images, trn_labels), (tst_images, tst_labels) = tfk.datasets.mnist.load_data()\n",
    "##### from N*28*28 to N*784 #####\n",
    "def rescale_and_flatten_images(images):\n",
    "    images = images.reshape((images.shape[0], 28*28)) / 255.\n",
    "    return images.astype('float32')\n",
    "trn_images = rescale_and_flatten_images(trn_images)[0:10000]\n",
    "tst_images = rescale_and_flatten_images(tst_images)[0:10000]\n",
    "trn_labels = trn_labels[0:10000]\n",
    "tst_labels = tst_labels[0:10000]\n",
    "print(trn_images.shape)\n",
    "print(trn_labels.shape)\n",
    "print(tst_images.shape)\n",
    "print(tst_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_images = np.concatenate([trn_images,Tmnist_images[0:10000]],axis=0)\n",
    "# trn_labels = np.concatenate([trn_labels,Tmnist_labels[0:10000]],axis=0)\n",
    "# tst_images = np.concatenate([tst_images,Tmnist_images[10000:20000]],axis=0)\n",
    "# tst_labels = np.concatenate([tst_labels,Tmnist_labels[10000:20000]],axis=0)\n",
    "# print(trn_images.shape)\n",
    "# print(trn_labels.shape)\n",
    "# print(tst_images.shape)\n",
    "# print(tst_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(20000)\n",
    "trn_images[indices]\n",
    "trn_labels[indices]\n",
    "indices = np.random.permutation(20000)\n",
    "tst_images[indices]\n",
    "tst_labels[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort it by labels(0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(trn_labels)\n",
    "trn_labels = trn_labels[sort_idx]\n",
    "trn_images = trn_images[sort_idx, :]\n",
    "print(trn_labels.shape)\n",
    "print(trn_images.shape)\n",
    "_, class_count = np.unique(trn_labels, return_counts=True)\n",
    "class_cumsum = np.cumsum(class_count)\n",
    "print('class count: ', class_count)\n",
    "print('class cumsum: ', class_cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag MNIST data into instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_idx = np.array([])\n",
    "for kk in np.arange(NUM_CLASS):\n",
    "    trim = (class_count[kk]//NUM_INSTANCES)*NUM_INSTANCES\n",
    "    if kk == 0:\n",
    "        bag_idx = np.hstack([bag_idx, np.arange(trim)])\n",
    "    else:\n",
    "        bag_idx = np.hstack([bag_idx, class_cumsum[kk-1]+np.arange(trim)])\n",
    "bag_idx = np.ix_(bag_idx.astype('int'))\n",
    "bagged_trn_labels = trn_labels[bag_idx].reshape((-1, NUM_INSTANCES))\n",
    "bagged_trn_images = trn_images[bag_idx, :].reshape((-1, NUM_INSTANCES, 28*28))\n",
    "print(bagged_trn_labels.shape)\n",
    "print(bagged_trn_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat dataset for distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = bagged_trn_images.shape[0]\n",
    "BATCH_SIZE_PER_REPLICA = 32\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "trn_dataset = (tf.data.Dataset\n",
    "                .from_tensor_slices(bagged_trn_images)\n",
    "                .shuffle(BUFFER_SIZE)\n",
    "                .batch(GLOBAL_BATCH_SIZE))\n",
    "trn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dist_dataset = strategy.experimental_distribute_dataset(trn_dataset)\n",
    "trn_dist_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define GVAE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleEncoder(tfkl.Layer):\n",
    "    \"\"\" Responsible for encoding the style of each instance.\n",
    "    Maps [?, instances, data_dim] -> [?, instances, sty_dim] (for mean and log-variance)\n",
    "    \"\"\"\n",
    "    def __init__(self, style_dim, mask_rate, name='style_encoder', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mask_rate = mask_rate\n",
    "        self.style_dim = style_dim\n",
    "        self.enc_per_instance = tfk.Sequential(\n",
    "                [   tfkl.Dense(512),\n",
    "                    tfkl.LeakyReLU(),\n",
    "                    tfkl.Dense(256),\n",
    "                    tfkl.LeakyReLU(),\n",
    "                    tfkl.Dense(style_dim),\n",
    "                    ],\n",
    "                    name=\"enc_per_instance\",)\n",
    "        self.enc_mean = tfk.Sequential(\n",
    "                [   tfkl.Dense(style_dim)\n",
    "                    ],\n",
    "                    name=\"z_mean\",)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        X = inputs \n",
    "        ninstances = inputs.shape[1]\n",
    "        data_dim = inputs.shape[2]\n",
    "        inputs =  tfkl.Reshape((-1, data_dim), name='flatten_instances')(inputs)\n",
    "        common = self.enc_per_instance(inputs)\n",
    "        z_mean = self.enc_mean(common)\n",
    "        # reshape back to [?, instances, style_dim]\n",
    "        z_mean = tfkl.Reshape((ninstances, self.style_dim))(z_mean)\n",
    "        z_mean = tfkl.Dropout(self.mask_rate)(z_mean)\n",
    "        return z_mean\n",
    "    \n",
    "class ContentEncoder(tfkl.Layer):\n",
    "    \"\"\" Responsible for encoding the content common to each instance.\n",
    "    \n",
    "    For GVAE the content encoder N(z|x1,...xk) has the parametric form\n",
    "    of N( \\avg \\mu(xi), \\avg s(xi), i.e. averaging a common encoder across instances.\n",
    "    \n",
    "    Maps [?, instances, data_dim] -> [?, 1, content_dim] (for mean and log-variance)\n",
    "    \"\"\"\n",
    "    def __init__(self, content_dim, name='style_encoder', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.content_dim = content_dim\n",
    "        self.enc_per_instance = tfk.Sequential(\n",
    "                [   tfkl.Dense(512),\n",
    "                    tfkl.LeakyReLU(),\n",
    "                    tfkl.Dense(256),\n",
    "                    tfkl.LeakyReLU(),\n",
    "                    tfkl.Dense(content_dim),\n",
    "                    ],\n",
    "                    name=\"enc_per_instance\",\n",
    "                )  \n",
    "        self.enc_mean = tfk.Sequential(\n",
    "                [   tfkl.Dense(content_dim)\n",
    "                    ],\n",
    "                    name=\"z_mean\",\n",
    "                )\n",
    "    def call(self, inputs):\n",
    "        X = inputs\n",
    "        ninstances = inputs.shape[1]\n",
    "        data_dim = inputs.shape[2]\n",
    "        inputs =  tfkl.Reshape((-1, data_dim), name='flatten_instances')(inputs)\n",
    "        common = self.enc_per_instance(inputs)\n",
    "        z_mean = self.enc_mean(common)\n",
    "        # reshape back to [?, instances, content_dim]\n",
    "        z_mean = tfkl.Reshape((ninstances, self.content_dim))(z_mean)\n",
    "        # compute average to [?, content_dim]\n",
    "        z_mean = tfkl.GlobalAveragePooling1D()(z_mean)  \n",
    "        # [?, content_dim] -> [?, 1, content_dim]\n",
    "        z_mean = tfkl.Reshape((1, self.content_dim))(z_mean)   \n",
    "        return z_mean\n",
    "    \n",
    "class Decoder(tfkl.Layer):\n",
    "    \"\"\" Decodes each pair of (z_content, z_instance)\n",
    "    \n",
    "    The number of instances is automatically inferred at runtime.\n",
    "    \n",
    "    Maps [?, instances, latent_dim] -> [?, instances, data_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dim, name='decoder', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.data_dim = data_dim     \n",
    "        self.dec_per_instance = tfk.Sequential(\n",
    "            [   tfkl.Dense(256),\n",
    "                tfkl.LeakyReLU(),\n",
    "                tfkl.Dense(512),\n",
    "                tfkl.LeakyReLU(),\n",
    "                tfkl.Dense(data_dim, activation='sigmoid'),\n",
    "            ],\n",
    "            name=\"dec_per_instance\",        \n",
    "        )\n",
    "\n",
    "    def call(self, z):\n",
    "        # infer number of instances [?, instances, latent_dim]\n",
    "        ninstances = z.shape[1]\n",
    "        latent_dim = z.shape[2]\n",
    "        # reshape instances to sample axis : [?*instances, latent_dim]\n",
    "        z = tfkl.Reshape((-1, latent_dim))(z)\n",
    "        # apply decoding to each instance : [?*instances, data_dim]\n",
    "        x_mean = self.dec_per_instance(z)\n",
    "        # collect instances : [?, instances, data_dim]\n",
    "        x_mean = tfkl.Reshape((ninstances, self.data_dim))(x_mean)\n",
    "        return x_mean\n",
    "    \n",
    "class SYMAE(tfk.Model):\n",
    "    \"\"\" Grouped Variational Auto-Encoder\n",
    "    [Input]\n",
    "        X ~ [?, instances, data_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dim, style_dim, content_dim, mask_rate,\n",
    "            nsamp=1, name='GVAE', dec_var_model ='trainable', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mask_rate = mask_rate\n",
    "        self.data_dim = data_dim\n",
    "        self.style_dim = style_dim\n",
    "        self.content_dim = content_dim\n",
    "        latent_dim = style_dim + content_dim\n",
    "        self.latent_dim = style_dim + content_dim\n",
    "\n",
    "        \"\"\" build encoder & decoder graphs \"\"\"\n",
    "        self.style_encoder = StyleEncoder(style_dim, mask_rate)\n",
    "        self.content_encoder = ContentEncoder(content_dim)\n",
    "        self.decoder = Decoder(data_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # input = [?, instances, data_dim]\n",
    "        X = inputs\n",
    "        ninstances = X.shape[1]\n",
    "        \"\"\" evaluate encoder/decoder \"\"\"        \n",
    "        # style encoding: [?, instances, data_dim] -> [?, instances, style_dim]\n",
    "        sty_mean = self.style_encoder(X)\n",
    "        # content encoding: [?, instances, data_dim] -> [?, 1, content_dim]\n",
    "        cnt_mean = self.content_encoder(X)\n",
    "        # replicate along instance dimension -> [?, instances, content_dim]\n",
    "        cnt_mean_replicate = tfkl.UpSampling1D(ninstances, name=\"replicate\")(cnt_mean)\n",
    "        # concatenate\n",
    "        z = tfkl.Concatenate(axis=-1)([sty_mean, cnt_mean_replicate])     \n",
    "        # decode\n",
    "        dec_mean = self.decoder(z)\n",
    "        \"\"\" compute ELBO loss \"\"\"\n",
    "        # squared error per example\n",
    "        se = tf.square(X - dec_mean) # [?, instances, data_dim]\n",
    "        se_per_instance = tf.reduce_sum(se, axis=-1) # [?, instances]\n",
    "        se_per_ex = tf.reduce_sum(se_per_instance, axis=-1) #[?, ]\n",
    "        return se_per_ex, dec_mean\n",
    "\n",
    "    def encode_decode(self, inputs):\n",
    "        \"\"\" Apply VAE deterministically: xhat = dec(enc(x))\"\"\"\n",
    "        X = inputs\n",
    "        ninstances = X.shape[1]  \n",
    "        \"\"\" evaluate encoder/decoder \"\"\"        \n",
    "        # style encoding: [?, instances, data_dim] -> [?, instances, style_dim]\n",
    "        sty_mean = self.style_encoder(X)\n",
    "        # content encoding: [?, instances, data_dim] -> [?, 1, content_dim]\n",
    "        cnt_mean = self.content_encoder(X)\n",
    "        # replicate along instance dimension -> [?, instances, content_dim]\n",
    "        cnt_mean_replicate = tfkl.UpSampling1D(ninstances, name=\"replicate\")(cnt_mean)\n",
    "        # concatenate:  [?, instances, latent_dim]\n",
    "        z = tfkl.Concatenate(axis=-1)([sty_mean, cnt_mean_replicate])  \n",
    "        # decode: [?, instances, data_dim]\n",
    "        dec_mean = self.decoder(z)\n",
    "        return dec_mean\n",
    "    \n",
    "    def content_encode(self, X):        \n",
    "        # content encoding: [?, instances, data_dim] -> [?, 1, content_dim]\n",
    "        cnt_mean = self.content_encoder(X)\n",
    "        return cnt_mean\n",
    "    \n",
    "    def style_encode(self, X):         \n",
    "        # style encoding: [?, instances, data_dim] -> [?, instances, style_dim]\n",
    "        sty_mean = self.style_encoder(X)\n",
    "        return sty_mean\n",
    "    \n",
    "    def style_decode(self, cnt_mean, sty_mean):\n",
    "        ninstances = sty_mean.shape[1]\n",
    "        # replicate along instance dimension -> [?, instances, content_dim]\n",
    "        cnt_mean_replicate = tfkl.UpSampling1D(ninstances)(cnt_mean)\n",
    "        # concatenate:  [?, instances, latent_dim]\n",
    "        z = tfkl.Concatenate(axis=-1)([sty_mean, cnt_mean_replicate])  \n",
    "        # decode: [?, instances, data_dim]\n",
    "        dec_mean = self.decoder(z)\n",
    "        return dec_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the weights stored in './checkpoint',\n",
    "set load_weights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    load_weights = True\n",
    "    style_dim = 20\n",
    "    content_dim = 20\n",
    "    data_dim = 28*28\n",
    "    mask_rate = 0.5\n",
    "    initial_learning_rate = 2e-4\n",
    "    ninstances = NUM_INSTANCES\n",
    "    symae = SYMAE(data_dim, style_dim, content_dim, mask_rate)\n",
    "    if load_weights == True:\n",
    "        symae.load_weights('./checkpoint')\n",
    "    lr_schedule = tfk.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate,\n",
    "                decay_steps=2000,\n",
    "                decay_rate=0.96,\n",
    "                staircase=True)\n",
    "    # opt = tf.optimizers.Adam(learning_rate=5e-4)\n",
    "    opt = tf.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    trn_loss_metric = tfk.metrics.Mean()\n",
    "    trn_mse_metric = tfk.metrics.Mean()\n",
    "    trn_sty_KL_metric = tfk.metrics.Mean()\n",
    "    trn_cnt_KL_metric = tfk.metrics.Mean()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set each training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mse_per_ex, _ = symae(inputs, training=True)\n",
    "        loss = tf.nn.compute_average_loss(mse_per_ex, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "    trn_loss_metric(mse_per_ex)\n",
    "    grads = tape.gradient(loss, symae.trainable_weights)\n",
    "    opt.apply_gradients(zip(grads, symae.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over epochs.\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):        \n",
    "    if epoch % 5 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "    print('===================', flush=True)\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for step, trn_batch in enumerate(trn_dist_dataset):\n",
    "        _ = distributed_train_step(trn_batch)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print('=== TRN ===')\n",
    "        #trn_batch = trn_batch.values[0].numpy()\n",
    "        trn_batch = trn_batch.numpy()\n",
    "        \"\"\" plot decoding of replicates \"\"\"\n",
    "        \"\"\" training loss \"\"\"\n",
    "        pred = symae.encode_decode(trn_batch)\n",
    "        pred = pred.numpy()       \n",
    "        plt.figure(figsize=(12,4), facecolor='w')\n",
    "        num_instance_plot = min([5, NUM_INSTANCES])\n",
    "        for kk in np.arange(num_instance_plot):\n",
    "            plt.subplot(2, num_instance_plot, kk+1)\n",
    "            plt.imshow(trn_batch[0,kk,:].reshape(28,28))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            if kk == 0:\n",
    "                plt.ylabel('Exact')            \n",
    "            plt.subplot(2, num_instance_plot, num_instance_plot+kk+1)\n",
    "            plt.imshow(pred[0,kk,:].reshape(28,28))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            if kk == 0:\n",
    "                plt.ylabel('Pred') \n",
    "        fig_training = plt.gcf()\n",
    "        plt.show()\n",
    "        \n",
    "        \"\"\" plot styling of replicates \"\"\"\n",
    "        \"\"\" Redatuming \"\"\"\n",
    "        nsplot = 5 # number of style plots\n",
    "        content_code = symae.content_encode(trn_batch).numpy()\n",
    "        style_code = symae.style_encode(trn_batch).numpy()\n",
    "        plt.figure(figsize=(10,10), facecolor='w')\n",
    "        for jj in np.arange(nsplot):\n",
    "            styled_mean = symae.style_decode(content_code[[jj],:,:], style_code[[0],:,:])\n",
    "            styled_mean = styled_mean.numpy()\n",
    "            for kk in np.arange(nsplot):\n",
    "                if jj == 0:\n",
    "                    # plot the style of each instance inside the 0th bag\n",
    "                    plt.subplot(nsplot+1, nsplot+1, kk+2)\n",
    "                    plt.imshow(trn_batch[0,kk,:].reshape(28,28))\n",
    "                    plt.xticks([]); plt.yticks([]);\n",
    "                    if kk==0:\n",
    "                        plt.ylabel('Style')\n",
    "                else:\n",
    "                    if kk==0:\n",
    "                        # plot an instance to show the \"content\"\n",
    "                        plt.subplot(nsplot+1, nsplot+1, jj*(nsplot+1)+kk+1)\n",
    "                        plt.imshow(trn_batch[jj,0,:].reshape(28,28))\n",
    "                        plt.xticks([]); plt.yticks([]);\n",
    "                        if jj == 1:\n",
    "                            plt.title('Content')\n",
    "                    # style the jth bag with styles from the 0th bag\n",
    "                    plt.subplot(nsplot+1, nsplot+1, jj*(nsplot+1)+kk+2)\n",
    "                    plt.imshow(styled_mean[0,kk,:].reshape(28,28))\n",
    "                    plt.xticks([]); plt.yticks([]);\n",
    "        fig_redatuming = plt.gcf()\n",
    "        plt.show()\n",
    "        \n",
    "    print('mean loss = %.3f' % trn_loss_metric.result().numpy())\n",
    "    trn_loss_metric.reset_states()\n",
    "    print('epoch running time = %.2fs' % (time.perf_counter()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symae.save_weights('./checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot figures in our paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsplot = 5 # number of style plots\n",
    "content_code = symae.content_encode(trn_batch).numpy()\n",
    "style_code = symae.style_encode(trn_batch).numpy()\n",
    "plt.figure(figsize=(10,10), facecolor='w')\n",
    "for jj in np.arange(nsplot):\n",
    "    styled_mean = symae.style_decode(content_code[[jj],:,:], style_code[[0],:,:])\n",
    "    styled_mean = styled_mean.numpy()\n",
    "    for kk in np.arange(nsplot):\n",
    "        if jj == 0:\n",
    "            # plot the style of each instance inside the 0th bag\n",
    "            plt.subplot(nsplot+1, nsplot+1, kk+2)\n",
    "            plt.imshow(trn_batch[0,kk,:].reshape(28,28), cmap='Greys')\n",
    "            plt.xticks([]); plt.yticks([]);\n",
    "            if kk==0:\n",
    "                plt.ylabel('Style',fontsize=15)\n",
    "        else:\n",
    "            if kk==0:\n",
    "                # plot an instance to show the \"content\"\n",
    "                plt.subplot(nsplot+1, nsplot+1, jj*(nsplot+1)+kk+1)\n",
    "                plt.imshow(trn_batch[jj,0,:].reshape(28,28), cmap='Greys')\n",
    "                plt.xticks([]); plt.yticks([]);\n",
    "                if jj == 1:\n",
    "                    plt.title('Content',fontsize=15)\n",
    "            # style the jth bag with styles from the 0th bag\n",
    "            plt.subplot(nsplot+1, nsplot+1, jj*(nsplot+1)+kk+2)\n",
    "            plt.imshow(styled_mean[0,kk,:].reshape(28,28), cmap='Greys')\n",
    "            plt.xticks([]); plt.yticks([]);\n",
    "fig_redatuming = plt.gcf()\n",
    "plt.savefig(\"Mnist_style.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
