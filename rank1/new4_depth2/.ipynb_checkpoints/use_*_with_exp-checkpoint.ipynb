{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653c0a99-d178-4121-b9ce-ede762fdd228",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Rank-1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be705430-ca48-4b06-b2e7-e45f376e4c1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e44961-2ccf-4ece-91c8-3ea6d55ae695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79464c78-90d9-4773-9e3b-b9e4f822c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 23:33:16.398670: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re,os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from tqdm import trange\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfkltd= tf.keras.layers.TimeDistributed\n",
    "clear_output()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89dd1f-f051-49f8-9098-7ce140285bf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import custom packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f6e4f-a152-4ccf-8a01-4bcdd632fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import generate\n",
    "from plot_training import plot_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a3efd-bbec-4b17-9959-29a0230b8c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058abe7-f44b-4ac2-9094-e3eade1dd0b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a959b-8479-4d61-87fb-018bc497ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 10\n",
    "n2 = 100\n",
    "nx = 50\n",
    "nt = 20\n",
    "p = 1\n",
    "q = 10\n",
    "states = np.arange(n1)\n",
    "nuisances = np.arange(n2)*n1\n",
    "#states = np.array([3,5,7,11,19,29,61,137,313,503])\n",
    "#nuisances = np.array([1,2,4,8,16,32,64,128,256,512])\n",
    "path = './p=%d,q=%d'%(p,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17fecee-96f0-4549-ad74-c662130ef721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71de487-0b37-4ab8-afc8-a6799c01bfd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ee958-8cc2-44f2-a17f-e4fbcc36433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate(states,nuisances,nx,nt,replace=0)\n",
    "X = data.X\n",
    "X_states = data.X_states\n",
    "X_nuisances = data.X_nuisances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a94da-0ee5-400f-ac88-fe48bbbd426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(data.D.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb73e1e-f4b3-45ae-a67a-58cb4af0c857",
   "metadata": {
    "tags": []
   },
   "source": [
    "### What blocks in D is selected by X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6c4f6-3e72-4489-a487-7fcac4782ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_samples = data.waiting_samples\n",
    "D_selected = np.ones((n1,n2))\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        D_selected[i][waiting_samples[i]] = 0    \n",
    "plt.figure(figsize=(5,5),dpi=100)\n",
    "plt.matshow(data.selected_times.T, fignum=1)\n",
    "plt.ylabel('nuisances');plt.xlabel('states')\n",
    "plt.xticks(range(n1));plt.yticks(range(n2))\n",
    "plt.gca().set_xticks([x - 0.5 for x in plt.gca().get_xticks()][1:], minor='true')\n",
    "plt.gca().set_yticks([y - 0.5 for y in plt.gca().get_yticks()][1:], minor='true')\n",
    "plt.grid(which='minor')\n",
    "plt.title('How many times has each block in D been selected')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06811a0-65cb-4021-86c9-ab0a3a52f03d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set SymAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690debcf-bcae-47ea-9dae-78cc7ab90105",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9da29-6361-42d5-be5e-ca01ba728a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmetricEncoderDense0D(tf.keras.Model):\n",
    "    def __init__(self, p, nt):\n",
    "        super(SymmetricEncoderDense0D, self).__init__(name='sym_encoder')\n",
    "        self.nt_out=p\n",
    "        self.nt_in=nt\n",
    "        self.d1=tfkl.Dense(p)\n",
    "    def call(self, x, training=False):\n",
    "        x=tf.math.reduce_mean(x,axis=1)\n",
    "        x=self.d1(x)\n",
    "        return x\n",
    "# 你是在让 nuisance encoder 记住states\n",
    "class NuisanceEncoderDense0D(tf.keras.Model):\n",
    "    def __init__(self, q, nt):\n",
    "        super(NuisanceEncoderDense0D, self).__init__(name='nui_encoder')\n",
    "        self.d1=tfkl.Dense(10000, activation=tf.keras.layers.LeakyReLU())\n",
    "        self.d2=tfkl.Dense(q)\n",
    "    def call(self, x, training=False):\n",
    "        x=self.d1(x)\n",
    "        x=self.d2(x)\n",
    "        return x\n",
    "class DistributeZsym(tf.keras.Model):\n",
    "    def __init__(self, ntau, nz0, nzi):\n",
    "        super(DistributeZsym, self).__init__(name='dist')\n",
    "        self.nz0=nz0\n",
    "        self.nzi=nzi\n",
    "        self.ntau=ntau\n",
    "        self.ri=tfkl.Reshape(target_shape=(ntau,nzi))\n",
    "        self.repeat=tfkl.RepeatVector(ntau)\n",
    "    def call(self, z, training=False):\n",
    "        z0,zi=tf.split(z,[self.nz0, self.ntau*self.nzi],axis=1)\n",
    "        zi=self.ri(zi)\n",
    "        z0=self.repeat(z0)\n",
    "        out=tfkl.concatenate([z0, zi],axis=2)\n",
    "        return out\n",
    "class MixerDense0D(tf.keras.Model):\n",
    "    def __init__(self, n_out=1, n_in=p+q):\n",
    "        super(MixerDense0D, self).__init__(name='mixer')\n",
    "        self.d1=tfkl.Dense(10000, activation=tf.keras.layers.LeakyReLU())\n",
    "        self.d2=tfkl.Dense(1)\n",
    "    def call(self, x, training=False):\n",
    "        #x=self.d1(x)\n",
    "        x=tf.math.reduce_sum(x, axis=-1, keepdims=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8b991-282c-4927-83d8-82f289bab0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentCat(tf.keras.Model):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        super(LatentCat, self).__init__(name='latentcat')\n",
    "        self.drop = tfkl.Dropout(alpha)\n",
    "    def call(self, zsym, znuisance, training=False):\n",
    "        znuisance = self.drop(znuisance, training=training)\n",
    "        znuisance = tfkl.Flatten()(znuisance)\n",
    "        z = tfkl.concatenate([zsym, znuisance])\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e81c4-51e1-4626-aa1d-5584e59e2cc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f6d94-06b3-476a-8898-0b22d2d93401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymAE(tf.keras.Model):\n",
    "    def __init__(self, N, nt, p, q, dropout_rate): \n",
    "        super(SymAE, self).__init__()\n",
    "        # Build symmetric encoder\n",
    "        sym_encoder = SymmetricEncoderDense0D(p,nt)\n",
    "        self.sym_encoder=sym_encoder\n",
    "        # Build nuisance encoder\n",
    "        nui_encoder = NuisanceEncoderDense0D(q,nt)\n",
    "        self.nui_encoder = nui_encoder\n",
    "        #Build latentcat\n",
    "        latentcat = LatentCat(alpha=dropout_rate)\n",
    "        self.latentcat = latentcat  \n",
    "        # Build distribute in decoder\n",
    "        distzsym = DistributeZsym(nt, p, q)\n",
    "        self.distzsym = distzsym\n",
    "        #Build mixer in decoder\n",
    "        mixer = MixerDense0D(1,p+q)\n",
    "        self.mixer = mixer\n",
    "        # Build encoder\n",
    "        encoder_input = tfk.Input(shape=(nt,1), dtype='float32', name='encoder_input')\n",
    "        znuisance = nui_encoder(encoder_input)\n",
    "        zsym = sym_encoder(encoder_input)\n",
    "        encoder_output=latentcat(zsym,znuisance)\n",
    "        encoder=tfk.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "        self.encoder=encoder\n",
    "        # Build decoder\n",
    "        decoder_input = tfk.Input(shape=(p+q*nt), name='latentcode')\n",
    "        decoder_output=mixer(distzsym(decoder_input))\n",
    "        decoder=tfk.Model(decoder_input,decoder_output, name=\"decoder\") \n",
    "        self.decoder=decoder\n",
    "    def call(self, input_tensor, training=False):\n",
    "        return self.decoder(self.encoder(input_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef994434-2a26-48a6-9afe-fdfd50d78eea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize SymAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2d7ce-0130-4236-a618-1bf22b325251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SymAE(nx,nt,p,q,0.5)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72a76f-04d2-4280-bfd6-dcfca905f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path+'/checkpoint')\n",
    "    print(\"weight exists\")\n",
    "except:\n",
    "    print(\"weight doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc633d-5a86-4f50-be84-3efc35afea57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992c7e7-1c7e-4082-ae45-529e8ee0aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.latentcat.drop.rate = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81f827-25f5-4801-9ae7-2b81e857c0eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25761b5-cfc5-4881-b4ae-7f6c3cab9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)\n",
    "SGD = tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.0,nesterov=False)\n",
    "model.compile(loss='mse',optimizer=Adam)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcfa5e-a3d0-4828-8319-6eae09671606",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d87da5-0adf-4aeb-bbf2-eaa0887828c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=10000\n",
    "epochs=range(M)\n",
    "losses=[np.nan]*M\n",
    "redata=[np.nan]*M\n",
    "sample_size = 10\n",
    "redatum_list = list(zip(np.random.randint(0,nx,sample_size),np.random.randint(0,nx,sample_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206f2c0-2b58-41e9-99f2-d172a6018e92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19911a-85f1-48ef-a678-39e1fc84f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f5d0d-d0f3-461f-990f-6dc418e0348c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b82d3-85bc-4923-af21-62e549e5a5d1",
   "metadata": {},
   "source": [
    "### From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad610d5b-e413-4d4f-b169-1c5375611e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def redatum(X1, X2):\n",
    "    return model.decoder(model.latentcat(model.sym_encoder(X1), model.nui_encoder(X2)))\n",
    "@tf.function\n",
    "def redatum_loss(X):\n",
    "    s = []\n",
    "    for (i1,i2) in redatum_list:\n",
    "        X1 = X[i1:i1+1]\n",
    "        X2 = X[i2:i2+1]\n",
    "        s.append(mse(redatum(X1,X2), states[X_states[i1]]+nuisances[X_nuisances[i2,:]]))\n",
    "    return sum(s)/sample_size\n",
    "@tf.function\n",
    "def reconstruction_loss(model, x, training=False):\n",
    "    x_hat = model(x, training=True)\n",
    "    return mse(x, x_hat)\n",
    "@tf.function\n",
    "def train_step(model, x, training=True):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_rec = reconstruction_loss(model, x, training)\n",
    "        loss = loss_rec\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7bf4f-6256-4d9d-81e7-b66a4736e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10000):\n",
    "    loss_rec = train_step(model, X)\n",
    "    print(\"For epoch {:d}, reconstruction loss is {:f}.\"\n",
    "          .format(epoch, loss_rec))\n",
    "    losses[epoch]=loss_rec\n",
    "    redata[epoch]=redatum_loss(X)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77191ac5-c4d1-4aa5-8514-3c26a7bf01f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffda753-bcfd-4b2d-b524-d15e0eb562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame(tf.reshape(model.nui_encoder(X),[-1,q]), columns = ['latent nuisance'])\n",
    "# df2 = pd.DataFrame(nuisances[X_nuisances.reshape(-1,1)],columns=['nuisance'])\n",
    "# df3 = pd.DataFrame(np.repeat(states[X_states],nt,axis=0),columns=['state'])\n",
    "# df4 = pd.DataFrame(np.zeros(df1.shape[0]),columns=['0'])\n",
    "# df = pd.concat([df1,df2,df3,df4],axis=1)\n",
    "# fig = px.scatter(df, x='latent nuisance', color='nuisance', y='0')\n",
    "# fig.update_layout(title=\"For epoch {:d}, reconstruction loss is {:f}.\"\n",
    "#       .format(epoch, loss_rec))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c3ef1-6123-4d3b-8071-63c08375c3de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loss-epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524add1-6c48-42dd-bb86-59dad136ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(epochs,losses,'C0')\n",
    "ax2.plot(epochs,redata,'C1')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss', color='C0')\n",
    "ax2.set_ylabel('redatum loss', color='C1')\n",
    "plt.savefig(path+'train.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20516808-4ee3-48c4-aeb8-07b94b35f70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187e4f4-629d-4b71-93fc-a980a3d2a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('./checkpoint/'+datetime.now().strftime(\"%B%d\"))\n",
    "model.save_weights(path+'/checkpoint')\n",
    "print(\"weights saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee184d-2805-4ee6-9b70-14cf842cbeef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601987e-cc5d-481b-8fa7-9f5ce90e06d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creat a dict mapping from subscripts of D to subscripts of X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e980e0d-abfe-426d-bbe4-28e4848954fb",
   "metadata": {},
   "source": [
    "This map is the inverse of X_states and X_nuisances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5260a-adda-498d-aa78-fafe05a457bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subscript_map = {}\n",
    "for i in range(nx):\n",
    "    for j in range(nt):\n",
    "        subscript_map[(X_states[i],X_nuisances[i,j])] = (i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0f6dd-1351-43fa-967f-9a6feab99383",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot D and SymAE(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da7f28-8575-4bc3-a2c7-660c4cdabd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = data.D\n",
    "X_hat = model.predict(X)[:,:,0]\n",
    "X_converted_max = np.empty((n1,n2))\n",
    "X_converted_max.fill(-np.inf)\n",
    "X_converted_min = np.empty((n1,n2))\n",
    "X_converted_min.fill(np.inf)\n",
    "for i in range(nx):\n",
    "    for j in range(nt):\n",
    "        i_D = X_states[i]\n",
    "        j_D = X_nuisances[i,j]\n",
    "        X_converted_max[i_D,j_D] = max(X_hat[i,j],X_converted_max[i_D,j_D])\n",
    "        X_converted_min[i_D,j_D] = min(X_hat[i,j],X_converted_max[i_D,j_D])\n",
    "def plot_reconstruct(D,X_converted):\n",
    "    fig, axs = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(10,5))\n",
    "    norm = mcolors.Normalize(vmin=np.amin(D), vmax=np.amax(D))\n",
    "    pcm = axs[0].matshow(D.T, norm = norm)\n",
    "    axs[0].set_ylabel('nuisances')\n",
    "    axs[0].set_xlabel('states')\n",
    "    axs[0].set_xticks(range(n1))\n",
    "    axs[0].set_yticks(range(n2))\n",
    "    axs[0].set_title('D')\n",
    "    pcm = axs[1].matshow(X_converted.T, norm = norm)\n",
    "    axs[1].set_ylabel('nuisances')\n",
    "    axs[1].set_xlabel('states')\n",
    "    axs[1].set_xticks(range(n1))\n",
    "    axs[1].set_yticks(range(n2))\n",
    "    axs[1].set_title('$\\hat{X}$')\n",
    "    fig.colorbar(pcm,ax=axs)\n",
    "    return fig\n",
    "fig = plot_reconstruct(D,X_converted_max)\n",
    "fig.suptitle('Training loss',fontsize=15)\n",
    "plt.show()\n",
    "#fig = plot_reconstruct(D,X_converted_min)\n",
    "#fig.suptitle('Training loss X_min',fontsize=15)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c980610-94b7-48b3-861a-3fb6e9297220",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize performance of redatuming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581475e-6a1b-4a60-adb9-299aac033294",
   "metadata": {},
   "source": [
    "### Evaluate latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22b999-76e5-42b2-bb93-3eb7b580724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = model.sym_encoder.predict(X, verbose=0)\n",
    "Ns = model.nui_encoder.predict(X, verbose=0)\n",
    "print(Cs.shape)\n",
    "print(Ns.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57f4ee-c9bc-485d-96fb-10f3293edc67",
   "metadata": {},
   "source": [
    "### Creat a dict, mapping from coordinates of missing blocks (in D) to coordinates i, i', j (in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ee0d7-65ec-4efa-9bea-dff4ca7f1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_map = {}\n",
    "for i_D in range(n1):\n",
    "    for j_D in range(n2):\n",
    "        state_candidates = np.argwhere(X_states==i_D) \n",
    "        nuisance_candidates = np.argwhere(X_nuisances==j_D) \n",
    "        i_s, = state_candidates[np.random.choice(state_candidates.shape[0])]\n",
    "        i_n, j_n = nuisance_candidates[np.random.choice(nuisance_candidates.shape[0])]\n",
    "        missing_map[i_D,j_D] = (i_n,i_s,j_n)\n",
    "for i_D in range(n1):\n",
    "    for j_D in range(n2):\n",
    "        i, i_prime, j = missing_map[i_D,j_D] \n",
    "        assert X_states[i_prime] == i_D\n",
    "        assert X_nuisances[i,j] == j_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac48a5-5783-4e98-b9c4-6769e887e1f8",
   "metadata": {},
   "source": [
    "### Define a function dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25700135-114d-4e8a-9421-93c1abc1d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec(latent_code):\n",
    "    tem = latent_code[np.newaxis, np.newaxis, :]\n",
    "    tem = np.repeat(tem, 1, axis=1)\n",
    "    tem = model.mixer.predict(tem, verbose=0)\n",
    "    return tem[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8803785-5cf0-40f8-8cf6-f85f737b71e0",
   "metadata": {},
   "source": [
    "### Fill out X_redatum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2abbb23-c73a-4043-8087-d9ef5def6376",
   "metadata": {},
   "source": [
    "Then we evaluate $\\hat{X}_{i_n \\to i_s}[j_n]$ and put it at X_redatum[i_D,j_D].  \n",
    "In the code below, i=i_n, i_prime=i_s, j=j_n.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3396df-5679-4a7c-aa3f-0c66d8dc5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_redatum = np.copy(X_converted_max)\n",
    "coherent_i_prime = np.empty((1,p))\n",
    "nuisance_i_j = np.empty((1,q*nt))\n",
    "for (i_D,j_D) in missing_map.keys():\n",
    "    i,i_prime,j = missing_map[i_D,j_D]\n",
    "    coherent_i_prime = Cs[i_prime,:]\n",
    "    nuisance_i_j = Ns[i,j]\n",
    "    merger = np.concatenate([coherent_i_prime,nuisance_i_j])\n",
    "    X_redatum[i_D,j_D] = dec(merger)  \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f5495-9f58-4291-9041-b4bdbd7ee277",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158842a-93b6-4b1b-9bd8-f1a81dc0a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_reconstruct(D,X_redatum)\n",
    "fig.suptitle('Redatuming',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ce226c-c525-41c1-97ac-7b3d5ae11ba5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3248b036-4b79-418a-adeb-07c423ea288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_reshaped = list(map(tuple, np.repeat(Cs, nt, axis=0))) \n",
    "N_reshaped = list(map(tuple, Ns.reshape(-1,q)))\n",
    "state_reshaped = states[np.repeat(X_states, nt, axis=0)]\n",
    "nuisance_reshaped = nuisances[X_nuisances.reshape(-1,1)[:,0]]\n",
    "data_dict = {'latent state':C_reshaped,\n",
    "             'latent nuisance':N_reshaped,\n",
    "             'true state':state_reshaped,\n",
    "             'true nuisance':nuisance_reshaped}\n",
    "C_pca = list(map(tuple,PCA(min(3,p)).fit_transform(C_reshaped)))\n",
    "N_pca = list(map(tuple,PCA(min(3,q)).fit_transform(N_reshaped)))\n",
    "data_dict['PCA latent state'] = C_pca\n",
    "data_dict['PCA latent nuisance'] = N_pca\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ffa857-8b3d-4694-97c9-99b2af67906a",
   "metadata": {},
   "source": [
    "### p-space (latent coherent space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68eb60c-e5dc-4d81-b0d5-12f8cf79251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p==1:\n",
    "    df = pd.DataFrame(Cs, columns = ['1st'])\n",
    "    df = pd.concat([df,pd.DataFrame(X_states,columns=['state'])],axis=1)\n",
    "    fig = px.scatter(df, x='1st', color='state')\n",
    "    fig.show()\n",
    "elif p==2:\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_C = pca.fit_transform(Cs)\n",
    "    df = pd.DataFrame(pca_C, columns = ['1st','2nd'])\n",
    "    tem = pd.DataFrame(X_states,columns=['state'])\n",
    "    df = pd.concat([df,tem],axis=1)\n",
    "    df.sort_values('state',inplace=True)\n",
    "    fig = px.scatter(df, x='1st', y='2nd', color='state')\n",
    "    fig.update_layout(title_text='p space PCA')\n",
    "    fig.show()\n",
    "elif p>=3:\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_C = pca.fit_transform(Cs)\n",
    "    df = pd.DataFrame(pca_C, columns = ['1st','2nd','3rd'])\n",
    "    tem = pd.DataFrame(X_states,columns=['state'])\n",
    "    df = pd.concat([df,tem],axis=1)\n",
    "    df.sort_values('state',inplace=True)\n",
    "    fig = px.scatter_3d(df, x='1st', y='2nd', z='3rd', color='state')\n",
    "    fig.update_layout(title_text='p space PCA')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a562b1-28ee-48da-ab85-d5da707dadd2",
   "metadata": {},
   "source": [
    "### q space (latent nuisance space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a137aaf-614c-426a-a85d-3b7b0bd97e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_N = Ns.reshape(-1,q)\n",
    "df = pd.DataFrame(pca_N, columns = np.arange(q))\n",
    "tem = pd.DataFrame(X_nuisances.reshape(-1,1),columns=['nuisance'])\n",
    "df = pd.concat([df,tem],axis=1)\n",
    "tem = pd.DataFrame(np.repeat(X_states,nt,axis=0),columns=['state'])\n",
    "df = pd.concat([df,tem],axis=1)\n",
    "fig = px.scatter(df, x='nuisance', y=4, color='state')\n",
    "fig.update_layout(title_text='q space PCA')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716780a5-dc28-44b4-a587-23ccc8b7e8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffeaf0-4e88-4ff9-ab56-9e5fe7c917f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c38189-6efd-48cc-a7b4-b97e30e6ad9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3bcb6-8021-418d-a842-067fa3f0c80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8416a6-3df4-491e-ab78-24aaaf807705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88352a83-434c-430f-8210-336baaa63605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c3841-2a03-4295-83a9-75af75ab1748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c4369-3551-49b9-bb64-43b185fc8af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdab89-6f81-4070-a0c3-94faf8ba3b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeae2ac-201d-457d-847e-c3a50307b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
