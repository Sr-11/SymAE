{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Kh93SwGY4ZwV"
   },
   "outputs": [],
   "source": [
    "#PURPOSE: Check CPU Capability\n",
    "import os, sys, time, glob, io, pprint, re, shutil\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import random\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1jlcfE54jHB",
    "outputId": "032bab44-5461-4139-9832-dfe769e26861"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7jvGClhUcppP"
   },
   "outputs": [],
   "source": [
    "#Plot Data Function\n",
    "def plot_data_heatmap(data, ID = 'N/A', water_pert='N/A'):\n",
    "  datap = np.transpose(data) \n",
    "  #------------------------------------------------------------------------------------------------------------------------\n",
    "  #Plot data\n",
    "  fig1 = plt.figure(figsize=(8,8))\n",
    "  plt.title('Model ' + str(ID) +  '   (' + str(water_pert) + '% pertubation)', fontsize = 15, pad =12)\n",
    "  plt.tick_params(axis='both', labelsize=12)\n",
    "  im1 = plt.imshow((datap), aspect='auto', cmap='RdBu', extent = [0, 100, 5896, 1250])\n",
    "  plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "  plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "  cbar = fig1.colorbar(im1)\n",
    "  cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "  plt.clim(-5,5)\n",
    "  #fname = 'MIT Images/SYMAE/Variable Seafloor/Shot_gather_0001.00.png'\n",
    "  #plt.savefig(fname)\n",
    "  plt.show()\n",
    "  return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "7TGnaA_U4Zwa",
    "outputId": "fc52b350-0adb-4a67-b631-f678ca870a16"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/content/drive/MyDrive/seismicTL_circular1_Brindha/ConstantSeafloor8.8s6.6vel/valconstantseafloor8.8s6.6vel_seismic.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m fnameval_ref_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/seismicTL_circular1_Brindha/ConstantSeafloor8.8s\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m vel_range \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvel/valconstantseafloor8.8s\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m vel_range \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvel_seismic_refs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m fnameval_ref_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/seismicTL_circular1_Brindha/ConstantSeafloor8.8s/valconstantseafloor8.8s_seismic_refs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m datval_w \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfnameval_w\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#val dataset\u001b[39;00m\n\u001b[1;32m     21\u001b[0m datval_ref_w\u001b[38;5;241m=\u001b[39mh5py\u001b[38;5;241m.\u001b[39mFile(fnameval_ref_w\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#val dataset\u001b[39;00m\n\u001b[1;32m     22\u001b[0m datval_n\u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(fnameval_n\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#val dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda/envs/MRA/lib/python3.9/site-packages/h5py/_hl/files.py:406\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m phil:\n\u001b[1;32m    405\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 406\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_fcpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack_order\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/software/anaconda/envs/MRA/lib/python3.9/site-packages/h5py/_hl/files.py:173\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    172\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 173\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    175\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:88\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/MyDrive/seismicTL_circular1_Brindha/ConstantSeafloor8.8s6.6vel/valconstantseafloor8.8s6.6vel_seismic.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "#Gather Data and Decide on Cropping the Shot Gather Dataset. \n",
    "#Information for cropping: \n",
    "##8.8s: time range: 8.845657725001187, n timesteps: 14262dt: 0.000620269106303989, sampling = 19\n",
    "##8.846/750 = 0.0118 = dt after sampling\n",
    "##when water velocity is the fastest, and seafloor is the highest, t for direct arrival = d/v = 2000m/1600ms-1 = 1.25s\n",
    "#1.25/0.0118 = 105 so fir cropping, we should be able to remove the first 105 time points from the 8.8s dataset.\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Set flags\n",
    "crop = True\n",
    "crop_start = 95 #95 for constant seafloor 8.8s 25.50 vel dataset, 105 for constant seafloor 8.8s dataset, 90 for constant seafloor dataset\n",
    "vel_range = '6.6'\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Retrieve and Crop Data (w stands for wide, n stands for narrow)\n",
    "fnameval_w = \"ConstantSeafloor8.8s\" + vel_range + \"vel/valconstantseafloor8.8s\" + vel_range + \"vel_seismic\"\n",
    "fnameval_n = \"ConstantSeafloor8.8s/valconstantseafloor8.8s_seismic\"\n",
    "\n",
    "fnameval_ref_w = \"ConstantSeafloor8.8s\" + vel_range + \"vel/valconstantseafloor8.8s\" + vel_range + \"vel_seismic_refs\"\n",
    "fnameval_ref_n = \"ConstantSeafloor8.8s/valconstantseafloor8.8s_seismic_refs\"\n",
    "\n",
    "datval_w = h5py.File(fnameval_w+\".h5\", 'r') #val dataset\n",
    "datval_ref_w=h5py.File(fnameval_ref_w+\".h5\", 'r') #val dataset\n",
    "datval_n= h5py.File(fnameval_n+\".h5\", 'r') #val dataset\n",
    "datval_ref_n=h5py.File(fnameval_ref_n+\".h5\", 'r') #val dataset\n",
    "\n",
    "if crop == False: \n",
    "    Xo_val_w=np.array(datval_w[\"data\"])[:,:,:,1:,:]\n",
    "    Xo_val_ref_w = np.array(datval_ref_w[\"data\"])[:,:,:,1:,:]\n",
    "    Xo_val_n=np.array(datval_n[\"data\"])[:,:,:,1:,:]\n",
    "    Xo_val_ref_n = np.array(datval_ref_n[\"data\"])[:,:,:,1:,:]\n",
    "\n",
    "if crop == True: \n",
    "    Xo_val_w=np.array(datval_w[\"data\"])[:,:,:,crop_start:655,:]\n",
    "    Xo_val_ref_w = np.array(datval_ref_w[\"data\"])[:,:,:,crop_start:655,:]\n",
    "    Xo_val_n=np.array(datval_n[\"data\"])[:,:,:,crop_start:655,:]\n",
    "    Xo_val_ref_n = np.array(datval_ref_n[\"data\"])[:,:,:,crop_start:655,:]\n",
    "\n",
    "#get information for each subsurface model and instance - from the perturbed category.   \n",
    "nsamp, ntau, n1, n2, nfilt=(700, 10, 100, 560, 1)\n",
    "nval = 100\n",
    "with open(str(fnameval_w+'.json')) as f:\n",
    "   labels_val_w = json.load(f)\n",
    "labels_val_w=[labels_val_w[i] for i in range(0,nval)]\n",
    "\n",
    "with open(str(fnameval_n+'.json')) as f:\n",
    "   labels_val_n = json.load(f)\n",
    "labels_val_n=[labels_val_n[i] for i in range(0,nval)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UnI8dw9YHKss"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xo_val_ref_w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m ref_sample_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m98\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#ref_sample_plot = random.randint(0, 20)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Retrieve data\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Take two random references and look at shot gathers to see the differences. Take reference gathers from wide dataset, though they should be identical to references from narrow dataset. \u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m reference_gather_1 \u001b[38;5;241m=\u001b[39m \u001b[43mXo_val_ref_w\u001b[49m[ref_sample_1:ref_sample_1\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:,:,:]\n\u001b[1;32m     15\u001b[0m reference_gather_2 \u001b[38;5;241m=\u001b[39m Xo_val_ref_w[ref_sample_2:ref_sample_2\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:,:,:]\n\u001b[1;32m     16\u001b[0m reference_gather_3 \u001b[38;5;241m=\u001b[39m Xo_val_ref_w[ref_sample_3:ref_sample_3\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:,:,:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xo_val_ref_w' is not defined"
     ]
    }
   ],
   "source": [
    "#Get datasets for splicing and redatuming   \n",
    "#We want a perturbated gather that has a significant deviation from the pertured\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Pick samples and instances for validation and reference gather\n",
    "val_sample = 0 #any number between 0 and 99 excluding the reference samples. (lets focus on 0,2,3,3) for models (901, 902, 903, 904)\n",
    "val_ins_plot = 7 #any number between 0 and 9\n",
    "ref_sample_1 = 86\n",
    "ref_sample_2 = 78\n",
    "ref_sample_3 = 98\n",
    "#ref_sample_plot = random.randint(0, 20)\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Retrieve data\n",
    "#Take two random references and look at shot gathers to see the differences. Take reference gathers from wide dataset, though they should be identical to references from narrow dataset. \n",
    "reference_gather_1 = Xo_val_ref_w[ref_sample_1:ref_sample_1+1,:,:,:,:]\n",
    "reference_gather_2 = Xo_val_ref_w[ref_sample_2:ref_sample_2+1,:,:,:,:]\n",
    "reference_gather_3 = Xo_val_ref_w[ref_sample_3:ref_sample_3+1,:,:,:,:]\n",
    "\n",
    "# #ten_reference_gathers = Xo_val_ref[ref_sample:ref_sample+10,:,:,:,:]\n",
    "# #Take validation gather sample and corresponding observed instances and reference instances. \n",
    "# perturbed_val_gather_1 = Xo_val[val_sample:val_sample+1,:,:,:,:] #0:1\n",
    "# perturbed_val_gather_2 = Xo_val[val_sample+1:val_sample+2,:,:,:,:]\n",
    "# perturbed_val_gather_3 = Xo_val[val_sample+2:val_sample+3,:,:,:,:] #0:1\n",
    "# perturbed_val_gather_4 = Xo_val[val_sample+3:val_sample+4,:,:,:,:]\n",
    "# reference_val_gather_1 = Xo_val_ref[val_sample:val_sample+1,:,:,:,:] #0:1\n",
    "# reference_val_gather_2 = Xo_val_ref[val_sample+1:val_sample+2,:,:,:,:] #0:1\n",
    "# reference_val_gather_3 = Xo_val_ref[val_sample+2:val_sample+3,:,:,:,:]\n",
    "# reference_val_gather_4 = Xo_val_ref[val_sample+3:val_sample+4,:,:,:,:]\n",
    "\n",
    "# val_reflector_depth = round(labels_val[val_sample][str(1)]['reflector_depth'], 3)\n",
    "# val_toplayer_vel = labels_val[val_sample][str(1)]['subsurface_velocities'][0]\n",
    "# val_ID = labels_val[val_sample][str(val_ins_plot)]['ID']\n",
    "# val_water_pert = round(labels_val[val_sample][str(val_ins_plot)]['water_pertubation'], 3)\n",
    "\n",
    "# ref_reflector_depth_1 = round(labels_val[ref_sample_1][str(1)]['reflector_depth'], 3)\n",
    "# ref_toplayer_vel_1 = labels_val[ref_sample_1][str(1)]['subsurface_velocities'][0]\n",
    "# ref_ID_1 = labels_val[ref_sample_1][str(1)]['ID']\n",
    "# ref_ID_1 = ref_ID_1[:5] + '00' #correct for instance number as it is a zero. \n",
    "\n",
    "# ref_reflector_depth_2 = round(labels_val[ref_sample_2][str(1)]['reflector_depth'], 3)\n",
    "# ref_toplayer_vel_2 = labels_val[ref_sample_2][str(1)]['subsurface_velocities'][0]\n",
    "# ref_ID_2 = labels_val[ref_sample_2][str(1)]['ID']\n",
    "# ref_ID_2 = ref_ID_2[:5] + '00' #correct for instance number as it is a zero.\n",
    "\n",
    "# ref_reflector_depth_3 = round(labels_val[ref_sample_3][str(1)]['reflector_depth'], 3)\n",
    "# ref_toplayer_vel_3 = labels_val[ref_sample_3][str(1)]['subsurface_velocities'][0]\n",
    "# ref_ID_3 = labels_val[ref_sample_3][str(1)]['ID']\n",
    "# ref_ID_3 = ref_ID_3[:5] + '00' #correct for instance number as it is a zero.\n",
    "\n",
    "# ref_water_pert = 0.00\n",
    "\n",
    "# print(\"perturbation value = \", str(val_water_pert))\n",
    "# print(\"shape of a_reference_gather\",np.shape(reference_gather_1))\n",
    "# #print(\"shape of ten_reference_gathers\",np.shape(ten_reference_gathers))\n",
    "# print(\"shape of perturbed_val_gather\",np.shape(perturbed_val_gather_1))\n",
    "# print(\"shape of reference_val_gather\",np.shape(reference_val_gather_1))\n",
    "\n",
    "# #------------------------------------------------------------------------------------------------------------------------\n",
    "# #View Validation Sample and View Reference Model\n",
    "# #View Validation Sample\n",
    "# valDataPlot = reference_val_gather_1[0,0,:,:,0]\n",
    "# refDataPlot1= reference_gather_1[0,0,:,:,0]\n",
    "# refDataPlot2= reference_gather_2[0,0,:,:,0]\n",
    "# refDataPlot3= reference_gather_3[0,0,:,:,0]\n",
    "\n",
    "# plot_data_heatmap(valDataPlot, ID = val_ID, water_pert=val_water_pert)\n",
    "# print (\"reflector depth: \", val_reflector_depth)\n",
    "# print (\"top layer velocity: \", val_toplayer_vel)\n",
    "# print (\"primary reflector time = 1.5+ (2621/2163)*2 = 3.92s\")\n",
    "\n",
    "\n",
    "# plot_data_heatmap(refDataPlot1, ID = ref_ID_1, water_pert=ref_water_pert)\n",
    "# print (\"reflector depth: \", ref_reflector_depth_1)\n",
    "# print (\"top layer velocity: \", ref_toplayer_vel_1)\n",
    "# print (\"primary reflector time = 1.5+ (2707/1886)*2 = 4.37s\")\n",
    "\n",
    "# plot_data_heatmap(refDataPlot2, ID = ref_ID_2, water_pert=ref_water_pert)\n",
    "# print (\"reflector depth: \", ref_reflector_depth_2)\n",
    "# print (\"top layer velocity: \", ref_toplayer_vel_2)\n",
    "# print (\"primary reflector time = 1.5+(2154/2354)*2 = 3.32s\")\n",
    "\n",
    "# plot_data_heatmap(refDataPlot3, ID = ref_ID_3, water_pert=ref_water_pert)\n",
    "# print (\"reflector depth: \", ref_reflector_depth_3)\n",
    "# print (\"top layer velocity: \", ref_toplayer_vel_3)\n",
    "# print (\"primary reflector time = 1.5+(1513/1998)*2 = 3.015s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFo3_xA24Zwe",
    "outputId": "4479e74e-1b68-490d-993b-4704da197970"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:21:56.770639: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.9.1\n",
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "#%% Load packages and setup GPU access\n",
    "# resources: https://jhui.github.io/2017/03/07/TensorFlow-GPU/\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfkltd= tf.keras.layers.TimeDistributed\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L4kUVIWE4Zwf"
   },
   "outputs": [],
   "source": [
    "class NuisanceEncoder(tf.keras.Model):\n",
    "  def __init__(self, kernel_sizes, filters, rdown=[2,2,1,1], tdown=[1,1,2,2], fstep=[2,4,8], latent_dim=7): #ori latent dimensions = 512\n",
    "    super(NuisanceEncoder, self).__init__()\n",
    "    k1,k2=kernel_sizes\n",
    "\n",
    "    # self.c1=tfkltd(tfkl.Conv2D(filters,(k1,k2),activation='elu'))\n",
    "    self.c1=tfkltd(tfkl.Conv2D(filters,(k1,k2),strides=(rdown[0],tdown[0]),activation='elu'))\n",
    "    # self.mp1=tfkltd(tfkl.MaxPool2D(pool_size=(rdown[0],tdown[0])))\n",
    "    # self.c3=tfkltd(tfkl.Conv2D(filters//fstep[0],(k1,k2),activation='elu'))\n",
    "    self.c4=tfkltd(tfkl.Conv2D(filters//fstep[0],(k1,k2),strides=(rdown[1],tdown[1]),activation='elu'))\n",
    "    # self.mp2=tfkltd(tfkl.MaxPool2D(pool_size=(rdown[1],tdown[1])))\n",
    "    self.c5=tfkltd(tfkl.Conv2D(filters//fstep[1],(k1,k2),strides=(rdown[2],tdown[2]),activation='elu'))\n",
    "    # self.c6=tfkltd(tfkl.Conv2D(filters//fstep[1],(k1,k2),activation='elu'))\n",
    "    # self.mp3=tfkltd(tfkl.MaxPool2D(pool_size=(rdown[2],tdown[2])))\n",
    "    # self.c7=tfkltd(tfkl.Conv2D(filters//fstep[2],(k1,k2),activation='elu'))\n",
    "    self.c8=tfkltd(tfkl.Conv2D(filters//fstep[2],(k1,k2),strides=(rdown[3],tdown[3]),activation='elu'))\n",
    "    self.bn=tfkltd(tfkl.BatchNormalization())\n",
    "    # self.mp4=tfkltd(tfkl.MaxPool2D(pool_size=(rdown[3],tdown[3])))\n",
    "    self.f=tfkltd(tfkl.Flatten())\n",
    "    self.d=tfkltd(tfkl.Dense(latent_dim))\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    # n, ntau, nr, nt, nc = input_tensor.get_shape()\n",
    "    x=self.c1(input_tensor)\n",
    "    # x=self.c2(x)\n",
    "    # x=self.mp1(x)\n",
    "    # x=self.c3(x)\n",
    "    x=self.c4(x)\n",
    "    # x=self.mp2(x)\n",
    "    x=self.c5(x)\n",
    "    # x=self.c6(x)\n",
    "    # x=self.mp3(x)\n",
    "    # x=self.c7(x)\n",
    "    x=self.c8(x)\n",
    "    x=self.bn(x, training=training)\n",
    "    # x=self.mp4(x)\n",
    "    x=self.f(x)\n",
    "    out=self.d(x)\n",
    "    return out\n",
    "  def model(self, x):\n",
    "    return tfk.Model(inputs=x, outputs=self.call(x))\n",
    "\n",
    "\n",
    "class SymmetricEncoder(tf.keras.Model):\n",
    "  def __init__(self, kernel_sizes, filters, rdown=[2,2,2,1], tdown=[2,4,4,4],latent_dim=8, fstep=[2,4,8]):\n",
    "    super(SymmetricEncoder, self).__init__()\n",
    "    k1,k2=kernel_sizes\n",
    "\n",
    "    self.c11=tfkltd(tfkl.Conv2D(filters,(k1,k2),activation='elu'))\n",
    "    self.c12=tfkltd(tfkl.Conv2D(filters//fstep[0],(k1,k2),strides=(rdown[0],tdown[0]),activation='elu'))\n",
    "    # self.mp11=tfkltd(tfkl.MaxPool2D(pool_size=(rdown[0],tdown[0])))\n",
    "    self.c13=tfkltd(tfkl.Conv2D(filters//fstep[1],(k1,k2),activation='elu'))\n",
    "    self.c14=tfkltd(tfkl.Conv2D(filters//fstep[2],(k1,k2),strides=(rdown[1],tdown[1]),activation='elu'))\n",
    "    # self.mp12=tfkltd(tfkl.MaxPool2D(pool_size=(rdown[1],tdown[1])))\n",
    "\n",
    "\n",
    "    self.c21=tfkl.Conv2D(filters,(k1,k2),strides=(rdown[2],tdown[2]),activation='elu')\n",
    "    # self.c22=tfkl.Conv2D(filters//fstep[0],(k1,k2),padding='same',activation='elu')\n",
    "    # self.mp21=tfkl.MaxPool2D(pool_size=(rdown[2],tdown[2]))\n",
    "    # self.c23=tfkl.Conv2D(filters//fstep[1],(k1,k2),padding='same',activation='elu')\n",
    "    self.c24=tfkl.Conv2D(filters//fstep[2],(k1,k2),strides=(rdown[3],tdown[3]),activation='elu')\n",
    "    self.bn=tfkl.BatchNormalization()\n",
    "    # self.mp22=tfkl.MaxPool2D(pool_size=(rdown[3],tdown[3]))\n",
    "    self.f=tfkl.Flatten()\n",
    "    self.d=tfkl.Dense(latent_dim)\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    # n, ntau, nr, nt, nc = input_tensor.get_shape()\n",
    "    x=self.c11(input_tensor)\n",
    "    x=self.c12(x)\n",
    "    # x=self.mp11(x)\n",
    "    x=self.c13(x)\n",
    "    x=self.c14(x)\n",
    "    # x=self.mp12(x)\n",
    "    x=tf.math.reduce_mean(x,axis=1)\n",
    "    x=self.c21(x)\n",
    "    # x=self.c22(x)\n",
    "    # x=self.mp21(x)\n",
    "    # x=self.c23(x)\n",
    "    x=self.c24(x)\n",
    "    x=self.bn(x, training=training)\n",
    "    # x=self.mp22(x)\n",
    "    x=self.f(x)\n",
    "    out=self.d(x)\n",
    "    return out\n",
    "  def model(self, x):\n",
    "    return tfk.Model(inputs=x, outputs=self.call(x))\n",
    "\n",
    "\n",
    "class DistributeZsym(tf.keras.Model):\n",
    "  def __init__(self, ntau, nz0, nzi):\n",
    "    super(DistributeZsym, self).__init__()\n",
    "\n",
    "    self.nz0=nz0\n",
    "    self.nzi=nzi\n",
    "    self.ntau=ntau\n",
    "    self.ri=tfkl.Reshape(target_shape=(ntau,nzi))\n",
    "    self.repeat=tfkl.RepeatVector(ntau)\n",
    "#     Xhatr=tfkl.Reshape(target_shape=(ntau,latent_dimr))(Xhatr)\n",
    "\n",
    "  def call(self, z, training=False):\n",
    "\n",
    "    z0,zi=tf.split(z,[self.nz0, self.ntau*self.nzi],axis=1)\n",
    "    zi=self.ri(zi)\n",
    "    z0=self.repeat(z0)\n",
    "    out=tfkl.concatenate([z0, zi],axis=2)\n",
    "    return out\n",
    "  def model(self, x):\n",
    "    return tfk.Model(inputs=x, outputs=self.call(x))\n",
    "\n",
    "\n",
    "class LatentCat(tf.keras.Model): #concatenates zsy, and znuisance with dropout. #dropout performed to create more noise -> a form of stochastic regularizatino to make training more noisy. \n",
    "  def __init__(self, alpha=1.0):\n",
    "    super(LatentCat, self).__init__()\n",
    "\n",
    "    self.drop=tfkl.GaussianDropout(alpha)\n",
    "    # self.drop=tfkl.Dropout(alpha)\n",
    "\n",
    "  def call(self, zsym, znuisance,training=False):\n",
    "    znuisance=self.drop(znuisance,training=training)\n",
    "    z=tfkl.concatenate([zsym, znuisance])\n",
    "    return z\n",
    "\n",
    "\n",
    "class Mixer(tf.keras.Model):\n",
    "  def __init__(self, kernel_sizes, filters, upfacts, nt, nr, fstep=[8,4,2]):\n",
    "    super(Mixer, self).__init__()\n",
    "    k1,k2=kernel_sizes\n",
    "    rup,tup=upfacts\n",
    "\n",
    "    filt_in=64\n",
    "\n",
    "    self.d1=tfkltd(tfkl.Dense(units=((nr//rup)*(nt//tup)*filt_in),activation='elu'))\n",
    "    self.r2=tfkltd(tfkl.Reshape(target_shape=((nr//rup),(nt//tup),filt_in)))\n",
    "    self.c1=tfkltd(tfkl.Conv2D(filters//fstep[0],(k1,k2),padding='same',activation='elu'))\n",
    "    self.us1=tfkltd(tfkl.UpSampling2D(size=(rup,tup)))\n",
    "    # self.c2=tfkltd(tfkl.Conv2D(filters//fstep[1],(k1,k2),padding='same',activation='elu'))\n",
    "    self.c3=tfkltd(tfkl.Conv2D(filters//fstep[1],(k1,k2),padding='same',activation='elu'))\n",
    "    self.bn=tfkltd(tfkl.BatchNormalization())\n",
    "    self.c4=tfkltd(tfkl.Conv2D(filters//fstep[2],(k1,k2),padding='same',activation='elu'))\n",
    "    # self.c5=tfkltd(tfkl.Conv2D(filters//fstep[2],(k1,k2),padding='same',activation='elu'))\n",
    "    self.c6=tfkltd(tfkl.Conv2D(1,(k1,k2),padding='same'))\n",
    "\n",
    "  def call(self, z, training=False):\n",
    "    x=self.d1(z)\n",
    "    x=self.r2(x)\n",
    "    x=self.us1(x)\n",
    "    x=self.c1(x)\n",
    "    # x=self.c2(x)\n",
    "    x=self.c3(x)\n",
    "    x=self.bn(x, training=training)\n",
    "    x=self.c4(x)\n",
    "    # x=self.c5(x)\n",
    "    out=self.c6(x)\n",
    "    return out\n",
    "  def model(self, x):\n",
    "    return tfk.Model(inputs=x, outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkCcloTe4Zwg",
    "outputId": "31dbc610-7961-4126-e7b2-bcf9f93e62f1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ntau' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder_input\u001b[38;5;241m=\u001b[39mtfk\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[43mntau\u001b[49m,n1,n2,\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder_input\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#input shape => 10, 50, 410 = ntau,n1,n2 ###NONE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m nfilt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m \u001b[38;5;66;03m#64\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ntau' is not defined"
     ]
    }
   ],
   "source": [
    "encoder_input=tfk.Input(shape=(ntau,n1,n2,1), dtype='float32', name='encoder_input') #input shape => 10, 50, 410 = ntau,n1,n2 ###NONE\n",
    "kernel_size=(5,5)\n",
    "nfilt=64 #64\n",
    "nz0=8 #symmetric encoder latent dimensions\n",
    "nzi=22 #nuisance encoder latent dimensions. \n",
    "\n",
    "\n",
    "symencoder1=SymmetricEncoder(kernel_size,nfilt,[2,2,2,2],[2,2,2,2],nz0, [1,1,1]) #initialize model\n",
    "xz0=symencoder1(encoder_input)\n",
    "z0=tfkl.Flatten()(xz0)\n",
    "nz0=z0.get_shape().as_list()[1]\n",
    "symencoder=tfk.Model(encoder_input, z0, name='symencoder')\n",
    "symencoder.summary()\n",
    "\n",
    "nencoder1=NuisanceEncoder(kernel_size,nfilt,[2,2,2,2],[2,2,2,2],[1,1,1],nzi) #initialize model\n",
    "xzi=nencoder1(encoder_input)\n",
    "zi=tfkl.Flatten()(xzi)\n",
    "nencoder=tfk.Model(encoder_input, zi, name='nencoder')\n",
    "nencoder.summary()\n",
    "\n",
    "decoder_input = tfk.Input(shape=(nzi*ntau+nz0), name='latentcode') #shape=(nzi*ntau+nz0) ###NONE\n",
    "\n",
    "distzsym1=DistributeZsym(ntau, nz0, nzi) #initialize model\n",
    "xdhat=distzsym1(decoder_input)\n",
    "distzsym = tfk.Model(decoder_input, xdhat, name='distzsym')\n",
    "distzsym.summary()\n",
    "\n",
    "\n",
    "mixer_input = tfk.Input(shape=(ntau,nzi+nz0), name='mixer_input') #DOES FUSING OF COHERENT INFORMATION WITH EACH INSTANCE OF THE NUISANCE INFORMATION.just a placeholder for mixer1. shape=(ntau,nzi+nz0) ###NONE\n",
    "\n",
    "mixer1=Mixer(kernel_size,nfilt,(10,10),n2,n1,[1,1,1]) #initialize model\n",
    "xhat=mixer1(xdhat) #mixer_input #xdhat\n",
    "mixer = tfk.Model(xdhat, xhat, name='mixer') #(mixer_input, xhat) #xdhat\n",
    "mixer.summary()\n",
    "\n",
    "znuisance=nencoder(encoder_input)\n",
    "zsym=symencoder(encoder_input)\n",
    "#xdist = distzsym(decoder_input)\n",
    "#xpredict = mixer(xdhat)\n",
    "\n",
    "#     report(upsampler,\"upsampler\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2ecFTPm4Zwh",
    "outputId": "3d9aaa34-f8db-46c6-cf3a-9aff06a46800"
   },
   "outputs": [],
   "source": [
    "latentcat=LatentCat(0.65) #0.4 droupout\n",
    "\n",
    "encoder=tfk.Model(encoder_input, latentcat(zsym,znuisance), name=\"encoder\") #latentcat(zsym,znuisance)\n",
    "encoder.summary()\n",
    "#tfk.utils.plot_model(encoder, show_shapes=True)\n",
    "\n",
    "decoder=tfk.Model(decoder_input, xhat, name=\"decoder\") #xpredict\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "px7xixen4Zwn",
    "outputId": "0f3f2a3b-df1e-4d8a-b61d-e3b34ec15ee1"
   },
   "outputs": [],
   "source": [
    "# Clone model structure and Load weights\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "#Set flags\n",
    "save_weights = False\n",
    "load_weights = True\n",
    "w_fn = \"chosen_temp_weights_120E_22nenc_0.65D_6.6vel\"\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "#Save weights\n",
    "#print(\"Previous Dropout \"+str(model.layers[2].layers[-1].rate))\n",
    "\n",
    "if save_weights: \n",
    "  fn = \"/content/drive/MyDrive/seismicTL_circular1_Brindha/Weights/\" + w_fn\n",
    "  model.save_weights(fn)\n",
    "\n",
    "#new_dropout=0.5\n",
    "#model.layers[2].layers[-1].rate=new_dropout\n",
    "#model = tfk.models.clone_model(model)\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "if load_weights:\n",
    "  model=tf.keras.Model(encoder_input, decoder(latentcat(zsym,znuisance)) , name='autoencoder_clone')\n",
    "  model.summary()\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  fn = \"/content/drive/MyDrive/seismicTL_circular1_Brindha/Weights/\" + w_fn\n",
    "  model.load_weights(fn)\n",
    "\n",
    "#print(\"New Dropout \"+str(model.layers[2].layers[-2].rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xl7AntoJLccq"
   },
   "outputs": [],
   "source": [
    "#Extract reference codes\n",
    "ten_identical_ref_gathers = np.tile(reference_gather_1, (10,1,1,1)) \n",
    "nuisance_reference = nencoder.predict(ten_identical_ref_gathers)\n",
    "#Extract wide validation codes\n",
    "coherent_wide = symencoder.predict(Xo_val_w[:,:,:,:,:])\n",
    "#Extract narrow validation codes\n",
    "coherent_narrow = symencoder.predict(Xo_val_n[:,:,:,:,:])\n",
    "#Redatum Codes\n",
    "nuisance_reference_tiled = np.tile(nuisance_reference, (100,1))\n",
    "hybrid_latent_wide = np.concatenate((coherent_wide,nuisance_reference_tiled),axis=1)\n",
    "hybrid_latent_narrow = np.concatenate((coherent_narrow,nuisance_reference_tiled),axis=1)\n",
    "corrected_wide=decoder.predict(hybrid_latent_wide)\n",
    "corrected_narrow=decoder.predict(hybrid_latent_narrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "93RWp7LtdH98",
    "outputId": "c221d334-45ea-4ccb-fe96-227ac8d2837e"
   },
   "outputs": [],
   "source": [
    "#Apply windowed cross-corelation on perturbed vs reference on model 901. \n",
    "#https://towardsdatascience.com/computing-cross-correlation-between-geophysical-time-series-488642be7bf0\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "#https://jinhyuncheong.com/jekyll/update/2019/05/16/Four_ways_to_qunatify_synchrony.html\n",
    "def crosscorr(datax, datay, lag=0, wrap=False):\n",
    "    \"\"\" Lag-N cross correlation.\n",
    "    Shifted data filled with NaNs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    if wrap:\n",
    "        shiftedy = datay.shift(lag)\n",
    "        shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "        return datax.corr(shiftedy)\n",
    "    else:\n",
    "        return datax.corr(datay.shift(lag))\n",
    "\n",
    "#Set Paramaters\n",
    "##-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "dt = (8.84565-1.121)/559\n",
    "print(\"dt:\", dt)\n",
    "time = np.linspace(start=1.121, stop=8.84565, num=560)\n",
    "mn =5\n",
    "inst =9 #+6% instance\n",
    "tr = 49\n",
    "window = 20\n",
    "step_size = 1\n",
    "\n",
    "#Run Code\n",
    "##-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "refsg = Xo_val_ref_w[mn, 0, tr, :, 0]\n",
    "p6sg = Xo_val_w[mn, inst, tr, :, 0]\n",
    "df = pd.DataFrame\n",
    "sr = pd.Series\n",
    "window=window+2\n",
    "t_start = 0\n",
    "t_end = t_start + window\n",
    "window_time = (window-2)*dt\n",
    "rss=[]\n",
    "\n",
    "while t_end < 560+window:\n",
    "    d1 = sr(refsg).iloc[t_start:t_end]\n",
    "    d2 = sr(p6sg).iloc[t_start:t_end]\n",
    "    rs = np.nan_to_num([crosscorr(d1,d2, lag, wrap=False) for lag in range(-int(window/2)+1,int(window/2))])\n",
    "    rss.append(rs)\n",
    "    t_start = t_start + step_size\n",
    "    t_end = t_end + step_size\n",
    "rss = df(rss)\n",
    "\n",
    "\n",
    "f,ax = plt.subplots(figsize=(12,8))\n",
    "ax2 = sns.heatmap(rss,cmap='RdBu_r',ax=ax)\n",
    "ax.set(title='Moving Window Cross-Correlation \\n Reference vs Instance (+6.0%)',xlim=[0,window], xlabel='Lag (s)',ylabel='Time (s)')\n",
    "ax.tick_params(axis='both', which='major', pad=5)\n",
    "a = [np.fix(item-(window-1)/2) for item in ax.get_xticks()]\n",
    "lags = [round(x * dt, 2) for x in a]\n",
    "#ax.set_ylabel(labelpad=15)\n",
    "ax.set_xticks(np.linspace(0,window-1,11))\n",
    "#ax.set_xticklabels([np.fix(item-(window-1)/2) for item in ax.get_xticks()])\n",
    "ax.set_xticklabels(lags)\n",
    "ax.set_yticks(np.linspace(0,len(rss),10))\n",
    "ax.set_yticklabels(np.around(np.linspace(start=1.121, stop=8.84565, num=10),3))\n",
    "ax.margins=30\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "ax.title.set_fontsize(17)\n",
    "ax2.figure.axes[-1].set_ylabel('Normalized correlation coefficient', size=14)\n",
    "plt.savefig(\"Correlation_Model901_Instance9_trace50_ref_perturbed6_title\")\n",
    "\n",
    "#seabed multiples\n",
    "window_start = 23\n",
    "window_start2 = 250 \n",
    "window_start3 = 479\n",
    "#reflector multiples\n",
    "window_start4 = 282\n",
    "window_start5 = 503\n",
    "mp1 = int(window_start + (window-2)/2)\n",
    "mp2 = int(window_start2 + (window-2)/2)\n",
    "mp3 = int(window_start3 + (window-2)/2)\n",
    "mp4 = int(window_start4 + (window-2)/2)\n",
    "mp5 = int(window_start5 + (window-2)/2)\n",
    "rss = rss.to_numpy()\n",
    "shift1=np.argmax(rss[mp1,:])-(window-2)/2\n",
    "shift2=np.argmax(rss[mp2,:])-(window-2)/2\n",
    "shift3=np.argmax(rss[mp3,:])-(window-2)/2\n",
    "shift4=np.argmax(rss[mp4,:])-(window-2)/2\n",
    "shift5=np.argmax(rss[mp5,:])-(window-2)/2\n",
    "ts1=np.around(shift1*dt, decimals=5)\n",
    "ts2=np.around(shift2*dt, decimals=5)\n",
    "ts3=np.around(shift3*dt, decimals=5)\n",
    "ts4=np.around(shift4*dt, decimals=5)\n",
    "ts5=np.around(shift5*dt, decimals=5)\n",
    "print(\"time-shift1: \", np.around(shift1*dt, decimals=5))\n",
    "print(\"time-shift2: \", np.around(shift2*dt, decimals=5))\n",
    "print(\"time-shift3: \", np.around(shift3*dt, decimals=5))\n",
    "print(\"time-shift4: \", np.around(shift4*dt, decimals=5))\n",
    "print(\"time-shift5: \", np.around(shift5*dt, decimals=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45dkIAIu3tOn",
    "outputId": "e3c683d4-dd38-4ea4-9b69-e739cae1b9ee"
   },
   "outputs": [],
   "source": [
    "a = [np.fix(item-(window-1)/2) for item in ax.get_xticks()]\n",
    "lags = [round(x * dt, 2) for x in a]\n",
    "print(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "RCirVVu-eEsO",
    "outputId": "5460c945-01de-4cda-8e29-7b1e12a51119"
   },
   "outputs": [],
   "source": [
    "#Set Paramaters\n",
    "##-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "dt = (8.84565-1.121)/559\n",
    "print(\"dt: \", dt)\n",
    "time = np.linspace(start=1.121, stop=8.84565, num=560)\n",
    "mn =5\n",
    "inst =9 #+6% instance\n",
    "tr = 49\n",
    "window = 18 #40\n",
    "step_size = 1\n",
    "\n",
    "#Run Code\n",
    "##-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "refsg = Xo_val_ref_w[mn, 0, tr, :, 0]\n",
    "c6sg = corrected_wide[mn, inst, tr, :, 0]\n",
    "df = pd.DataFrame\n",
    "sr = pd.Series\n",
    "window=window+2\n",
    "t_start = 0\n",
    "t_end = t_start + window\n",
    "window_time = (window-2)*dt\n",
    "rss=[]\n",
    "while t_end < 560+window:\n",
    "    d1 = sr(refsg).iloc[t_start:t_end]\n",
    "    d2 = sr(c6sg).iloc[t_start:t_end]\n",
    "    rs = np.nan_to_num([crosscorr(d1,d2, lag, wrap=False) for lag in range(-int(window/2)+1,int(window/2))])\n",
    "    rss.append(rs)\n",
    "    t_start = t_start + step_size\n",
    "    t_end = t_end + step_size\n",
    "rss = df(rss)\n",
    "\n",
    "f,ax = plt.subplots(figsize=(12,8))\n",
    "ax2 = sns.heatmap(rss,cmap='RdBu_r',ax=ax)\n",
    "ax.set(title='Moving Window Cross-Correlation \\n Reference vs Redatumed (+6.0%)',xlim=[0,window], xlabel='Offset (dt)',ylabel='Time (s)')\n",
    "ax.tick_params(axis='both', which='major', pad=5)\n",
    "ax.set_xticks(np.linspace(0,window-1,11))\n",
    "#ax.set_xticklabels([np.fix(item-(window-1)/2) for item in ax.get_xticks()])\n",
    "ax.set_xticklabels(lags)\n",
    "ax.set_yticks(np.linspace(0,len(rss),10))\n",
    "ax.set_yticklabels(np.around(np.linspace(start=1.121, stop=8.84565, num=10),3))\n",
    "ax.margins=30\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "ax.title.set_fontsize(17)\n",
    "ax2.figure.axes[-1].set_ylabel('Normalized correlation coefficient', size=14)\n",
    "plt.savefig(\"Correlation_Model901_Instance9_trace50_ref_redatumed6_title\")\n",
    "\n",
    "#seabed multiples\n",
    "window_start = 23\n",
    "window_start2 = 250 #228 #250\n",
    "window_start3 = 479 #458 #479\n",
    "#reflector multiples\n",
    "window_start4 = 282\n",
    "window_start5 = 503\n",
    "mp1 = int(window_start + (window-2)/2)\n",
    "mp2 = int(window_start2 + (window-2)/2)\n",
    "mp3 = int(window_start3 + (window-2)/2)\n",
    "mp4 = int(window_start4 + (window-2)/2)\n",
    "mp5 = int(window_start5 + (window-2)/2)\n",
    "rss = rss.to_numpy()\n",
    "shift1=np.argmax(rss[mp1,:])-(window-2)/2\n",
    "shift2=np.argmax(rss[mp2,:])-(window-2)/2\n",
    "shift3=np.argmax(rss[mp3,:])-(window-2)/2\n",
    "shift4=np.argmax(rss[mp4,:])-(window-2)/2\n",
    "shift5=np.argmax(rss[mp5,:])-(window-2)/2\n",
    "ts1=np.around(shift1*dt, decimals=5)\n",
    "ts2=np.around(shift2*dt, decimals=5)\n",
    "ts3=np.around(shift3*dt, decimals=5)\n",
    "ts4=np.around(shift4*dt, decimals=5)\n",
    "ts5=np.around(shift5*dt, decimals=5)\n",
    "print(\"time-shift1: \", np.around(shift1*dt, decimals=5))\n",
    "print(\"time-shift2: \", np.around(shift2*dt, decimals=5))\n",
    "print(\"time-shift3: \", np.around(shift3*dt, decimals=5))\n",
    "print(\"time-shift4: \", np.around(shift4*dt, decimals=5))\n",
    "print(\"time-shift5: \", np.around(shift5*dt, decimals=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90s3WXR3U1R5",
    "outputId": "90db404d-c7ba-454a-b394-e150467cadfb"
   },
   "outputs": [],
   "source": [
    "np.argmax(rss[mp2,:])-(window-2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0OH2eZbycMj"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import scipy.stats as stats\n",
    "# refsg = Xo_val_ref_w[mn, 0, tr, :, 0]\n",
    "# p6sg = Xo_val_w[mn, inst, tr, :, 0]\n",
    "# df = pd.DataFrame\n",
    "# sr = pd.Series\n",
    "# no_splits = 56\n",
    "# samples_per_split = refsg.shape[0]/no_splits\n",
    "# window=20\n",
    "# rss=[]\n",
    "# for t in range(0, no_splits):\n",
    "#     d1 = sr(refsg).loc[(t)*samples_per_split:(t+1)*samples_per_split]\n",
    "#     d2 = sr(p6sg).loc[(t)*samples_per_split:(t+1)*samples_per_split]\n",
    "#     rs = np.nan_to_num([crosscorr(d1,d2, lag) for lag in range(-int(window/2),int(window/2))])\n",
    "#     rss.append(rs) #list of list for each \n",
    "\n",
    "# f,ax = plt.subplots(figsize=(10,20))\n",
    "# sns.heatmap(rss,cmap='RdBu_r',ax=ax)\n",
    "# ax.set(title=f'(reference leads <) Windowed Time Lagged Cross Correlation (> perturbed leads)',xlim=[0,window], xlabel='Offset',ylabel='Window epochs')\n",
    "# ax.set_xticklabels([int(item-window/2) for item in ax.get_xticks()]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3m3m2Z1TXJC",
    "outputId": "cb5af3d7-93be-464c-a684-7fe7677e7532"
   },
   "outputs": [],
   "source": [
    "#np.shape(corrected_narrow)\n",
    "#Evaluate norms: \n",
    "from numpy import linalg as LA\n",
    "def norm(data1, data2):\n",
    "  '''data1 is true, data2 is corrected'''\n",
    "  data1 = np.transpose(data1)\n",
    "  data2 = np.transpose(data2)\n",
    "  num = data1-data2\n",
    "  denom = data1\n",
    "\n",
    "  num = LA.norm(num, 'fro')\n",
    "  denom = LA.norm(denom, 'fro')\n",
    "  norm_ratio = num/denom\n",
    "  return norm_ratio\n",
    "\n",
    "! pip install wiggle\n",
    "import wiggle as wiggle\n",
    "def plot_wiggle(x,c='k', txt='none', t=None, label_flag='off'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    # fig=plt.figure(dpi=150, figsize=(6,12))\n",
    "    sf=np.max(np.std(x,axis=1))\n",
    "    wiggle.wiggle(x.T, tt = t, color=c, sf= sf/0.5/10)#\n",
    "    # if(txt != 'none'):\n",
    "        # plt.text(0.5, 8, txt, size=20, color='black', bbox=dict(facecolor='red', alpha=1,))\n",
    "    plt.axis(label_flag)\n",
    "    # plt.savefig(os.path.join(dir,s), bbox_inches='tight')\n",
    "    # plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Vcg3frvgGDSF",
    "outputId": "adb9146e-cf1f-4293-cb8b-854848c78e7e"
   },
   "outputs": [],
   "source": [
    "#Plot traces with the same subsurface for fine combing comparison\n",
    "##-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#print(\"reference_gather_1.shape\", reference_gather_1[0, 0, 0:1, :, 0])\n",
    "print(\"corrected_narrow.shape\", corrected_narrow.shape)\n",
    "print(\"uncorrected narrow.shape\", Xo_val_n[:,:,:,:,:].shape)\n",
    "print(\"true/reference narrow.shape\", Xo_val_ref_n[:,:,:,:,:].shape)\n",
    "time = np.linspace(start=1.121, stop=8.84565, num=560)\n",
    "colors = plt.cm.viridis_r(np.linspace(0,1,6)) #reference on colormaps: https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "col = 'purple'\n",
    "plot_window= False\n",
    "#time.shape = 560\n",
    "# window_start2 = 228 #232  #248\n",
    "# window_start3 = 458   #475\n",
    "\n",
    "#Collect traces\n",
    "mn= 5#5 #model_number\n",
    "\n",
    "#trace0r.shape = (560,)\n",
    "trace0r = Xo_val_ref_w[mn, 0, 0, :, 0]\n",
    "trace49r = Xo_val_ref_w[mn, 0, 49, :, 0]\n",
    "trace99r = Xo_val_ref_w[mn, 0, 99, :, 0]\n",
    "#traceX.shape = (10,560)\n",
    "trace0 = corrected_wide[mn, :, 0, :, 0]\n",
    "trace49 = corrected_wide[mn, :, 49, :, 0]\n",
    "trace99 = corrected_wide[mn, :, 99, :, 0]\n",
    "#traceXp.shape = (10,560)\n",
    "trace0p = Xo_val_w[mn, :, 0, :, 0]\n",
    "trace49p = Xo_val_w[mn, :, 49, :, 0]\n",
    "trace99p = Xo_val_w[mn, :, 99, :, 0]\n",
    "\n",
    "fig1 = plt.figure(figsize=(30,7))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(trace0r, color='red', label=(\"Reference\"))\n",
    "# plt.plot(trace0p[0,:], color=colors[0], alpha=0.6,label=(\"-6.0% Instance\"))\n",
    "# plt.plot(trace0p[2,:], color=colors[1],alpha=0.6, label=(\"-5.0% Instance\"))\n",
    "# plt.plot(trace0p[4,:],color=colors[2], alpha=0.6,label=(\"-4.0% Instance\"))\n",
    "# plt.plot(trace0p[5,:],color=colors[3], alpha=0.6,label=(\"+4.0% Instance\"))\n",
    "# plt.plot(trace0p[7,:], color=colors[4],alpha=0.6, label=(\"+5.0% Instance\"))\n",
    "plt.plot(trace0p[9,:],color=colors[5], alpha=0.6,label=(\"+6.0% Instance\"))\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.title('Perturbed Far Offset (-3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(trace0r, color='red', label=(\"Reference\"))\n",
    "# plt.plot(trace0[0,:], color=colors[0], alpha=0.6,label=(\"-6.0% Instance\"))\n",
    "# plt.plot(trace0[2,:], color=colors[1],alpha=0.6, label=(\"-5.0% Instance\"))\n",
    "# plt.plot(trace0[4,:],color=colors[2], alpha=0.6,label=(\"-4.0% Instance\"))\n",
    "# plt.plot(trace0[5,:],color=colors[3], alpha=0.6,label=(\"+4.0% Instance\"))\n",
    "# plt.plot(trace0[6,:], color=colors[4],alpha=0.6, label=(\"+5.0% Instance\"))\n",
    "plt.plot(trace0[7,:],color=colors[5], alpha=0.6,label=(\"+6.0% Instance\"))\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.title('Redatumed Far Offset (-3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "fname = 'Trace 1 Model 901'\n",
    "#plt.savefig(fname)\n",
    "\n",
    "fig2 = plt.figure(figsize=(30,7))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(trace49r, color='red', label=(\"Reference\"))\n",
    "# plt.plot(trace49p[0,:], color=colors[0], alpha=0.6,label=(\"-6.0% Instance\"))\n",
    "# plt.plot(trace49p[2,:], color=colors[1],alpha=0.6, label=(\"-5.0% Instance\"))\n",
    "# plt.plot(trace49p[4,:],color=colors[2], alpha=0.6,label=(\"-4.0% Instance\"))\n",
    "# plt.plot(trace49p[5,:],color=colors[3], alpha=0.6,label=(\"+4.0% Instance\"))\n",
    "# plt.plot(trace49p[7,:], color=colors[4],alpha=0.6, label=(\"+5.0% Instance\"))\n",
    "plt.plot(trace49p[9,:],color=colors[5], alpha=0.6,label=(\"+6.0% Instance\"))\n",
    "\n",
    "plt.text(window_start+(window+10), 6, r'$\\Delta t_{1} = $'+str(ts1) + 's', fontsize=15)\n",
    "plt.text(window_start2+(window-45), 6, r'$\\Delta t_{3} = $'+str(ts2) + 's', fontsize=15)      #window-7 window-40\n",
    "plt.text(window_start3+(window-50), 6, r'$\\Delta t_{5} = $'+str(ts3) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start4+(window-30), -4.5, r'$\\Delta t_{2} = $'+str(ts4) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start5+(window-28), -4.5, r'$\\Delta t_{4} = $'+str(ts5) + 's', fontsize=15)      #window-24 window-40\n",
    "\n",
    "if plot_window:\n",
    "  plt.plot([window_start,window_start+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  plt.vlines(window_start, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.vlines(window_start+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5) \n",
    "  # plt.plot([window_start2,window_start2+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5, label=(\"Cross-Correlation Window\"))\n",
    "  # plt.vlines(window_start2, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.vlines(window_start2+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.plot([window_start3,window_start3+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  # plt.vlines(window_start3, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.vlines(window_start3+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.plot([window_start4,window_start4+(window-2)],[-2.5,-2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  # plt.vlines(window_start4, 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.vlines(window_start4+(window-2), 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.plot([window_start5,window_start5+(window-2)],[-2.5,-2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  # plt.vlines(window_start5, 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  # plt.vlines(window_start5+(window-2), 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Zero Offset', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(trace49r, color='red', label=(\"Reference\"))\n",
    "# plt.plot(trace49[0,:], color=colors[0], alpha=0.6,label=(\"-6.0% Instance\"))\n",
    "# plt.plot(trace49[2,:], color=colors[1],alpha=0.6, label=(\"-5.0% Instance\"))\n",
    "# plt.plot(trace49[4,:],color=colors[2], alpha=0.6,label=(\"-4.0% Instance\"))\n",
    "# plt.plot(trace49[5,:],color=colors[3], alpha=0.6,label=(\"+4.0% Instance\"))\n",
    "# plt.plot(trace49[7,:], color=colors[4],alpha=0.6, label=(\"+5.0% Instance\"))\n",
    "plt.plot(trace49[9,:],color=colors[5], alpha=0.6,label=(\"+6.0% Redatumed\"))\n",
    "\n",
    "plt.text(window_start+(window+10), 6, r'$\\Delta t_{1} = $'+str(0.00) + 's', fontsize=15)\n",
    "plt.text(window_start2+(window-45), 6, r'$\\Delta t_{3} = $'+str(0.00) + 's', fontsize=15)      #window-7 window-40\n",
    "plt.text(window_start3+(window-50), 6, r'$\\Delta t_{5} = $'+str(0.00) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start4+(window-30), -4.5, r'$\\Delta t_{2} = $'+str(0.00) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start5+(window-28), -4.5, r'$\\Delta t_{4} = $'+str(0.00) + 's', fontsize=15)      #window-24 window-40\n",
    "\n",
    "\n",
    "if plot_window:\n",
    "  plt.plot([window_start,window_start+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  plt.vlines(window_start, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.vlines(window_start+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.plot([window_start2,window_start2+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5, label=(\"Cross-Correlation Window\"))\n",
    "  plt.vlines(window_start2, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.vlines(window_start2+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.plot([window_start3,window_start3+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  plt.vlines(window_start3, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.vlines(window_start3+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.plot([window_start4,window_start4+(window-2)],[-2.5,-2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  plt.vlines(window_start4, 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.vlines(window_start4+(window-2), 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.plot([window_start5,window_start5+(window-2)],[-2.5,-2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "  plt.vlines(window_start5, 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "  plt.vlines(window_start5+(window-2), 0.0, -2.5, colors='blue', linestyles='solid', lw=5)\n",
    "\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Zero Offset', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "fname = 'Trace 50 Model 906 Timeshifts'\n",
    "plt.savefig(fname)\n",
    "\n",
    "fig3 = plt.figure(figsize=(30,7))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(trace99r, color='red', label=(\"Reference\"))\n",
    "plt.text(window_start+(window-120), 6, r'$\\Delta t_{1} = $'+str(ts1) + 's', fontsize=15)\n",
    "plt.text(window_start2+(window-50), 6, r'$\\Delta t_{3} = $'+str(ts2) + 's', fontsize=15)      #window-7 window-40\n",
    "plt.text(window_start3+(window-46), 6, r'$\\Delta t_{5} = $'+str(ts3) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start4+(window-39), -4.5, r'$\\Delta t_{2} = $'+str(ts4) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start5+(window-50), -4.5, r'$\\Delta t_{4} = $'+str(ts5) + 's', fontsize=15)     \n",
    "# plt.plot([window_start,window_start+(window-2)],[2.5,2.5],'blue',linestyle = 'dotted', lw=5)\n",
    "# plt.vlines(window_start, -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "# plt.vlines(window_start+(window-2), -0.2, 2.5, colors='blue', linestyles='solid', lw=5)\n",
    "# plt.plot(trace99p[0,:], color=colors[0], alpha=0.6,label=(\"-6.0% Instance\"))\n",
    "# plt.plot(trace99p[2,:], color=colors[1],alpha=0.6, label=(\"-5.0% Instance\"))\n",
    "# plt.plot(trace99p[4,:],color=colors[2], alpha=0.6,label=(\"-4.0% Instance\"))\n",
    "# plt.plot(trace99p[5,:],color=colors[3], alpha=0.6,label=(\"+4.0% Instance\"))\n",
    "# plt.plot(trace99p[7,:], color=colors[4],alpha=0.6, label=(\"+5.0% Instance\"))\n",
    "plt.plot(trace99p[9,:],color=colors[5], alpha=0.6,label=(\"+6.0% Instance\"))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Far Offset (+3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(trace99r, color='red', label=(\"Reference\"))\n",
    "plt.text(window_start+(window-120), 6, r'$\\Delta t_{1} = $'+str(0.00) + 's', fontsize=15)\n",
    "plt.text(window_start2+(window-50), 6, r'$\\Delta t_{3} = $'+str(0.00) + 's', fontsize=15)      #window-7 window-40\n",
    "plt.text(window_start3+(window-46), 6, r'$\\Delta t_{5} = $'+str(0.00) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start4+(window-35), -4.5, r'$\\Delta t_{2} = $'+str(0.01382) + 's', fontsize=15)      #window-24 window-40\n",
    "plt.text(window_start5+(window-35), -4.5, r'$\\Delta t_{4} = $'+str(0.00) + 's', fontsize=15) \n",
    "# plt.plot(trace99[0,:], color=colors[0], alpha=0.6,label=(\"-6.0% Instance\"))\n",
    "# plt.plot(trace99[2,:], color=colors[1],alpha=0.6, label=(\"-5.0% Instance\"))\n",
    "# plt.plot(trace99[4,:],color=colors[2], alpha=0.6,label=(\"-4.0% Instance\"))\n",
    "# plt.plot(trace99[5,:],color=colors[3], alpha=0.6,label=(\"+4.0% Instance\"))\n",
    "# plt.plot(trace99[7,:], color=colors[4],alpha=0.6, label=(\"+5.0% Instance\"))\n",
    "plt.plot(trace99[9,:],color=colors[5], alpha=0.6,label=(\"+6.0% Instance\"))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Far Offset (+3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "fname = 'Trace 100 Model 906 timeshifts'\n",
    "#plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eOaIIRIMG01N",
    "outputId": "db452705-07c7-4581-a854-ba662eefff08"
   },
   "outputs": [],
   "source": [
    "#Plot traces across different subsurfaces to see if seabed multiples arrive at the same time, albeit with different amplitudes\n",
    "##-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#print(\"reference_gather_1.shape\", reference_gather_1[0, 0, 0:1, :, 0])\n",
    "print(\"corrected_narrow.shape\", corrected_narrow.shape)\n",
    "print(\"uncorrected narrow.shape\", Xo_val_n[:,:,:,:,:].shape)\n",
    "print(\"true/reference narrow.shape\", Xo_val_ref_n[:,:,:,:,:].shape)\n",
    "time = np.linspace(start=1.121, stop=8.84565, num=560)\n",
    "colors = plt.cm.viridis_r(np.linspace(0,1,6)) #reference on colormaps: https://stackoverflow.com/questions/38208700/matplotlib-plot-lines-with-colors-through-colormap\n",
    "#time.shape = 560\n",
    "\n",
    "#Collect traces\n",
    "trace0p = Xo_val_w[0, 0, 0, :, 0]\n",
    "# trace0 = corrected_wide[0:nmodels-1, 0, 0, :, 0]\n",
    "# trace49 = corrected_wide[0:nmodels-1, 0, 49, :, 0]\n",
    "# trace99 = corrected_wide[0:nmodels-1, 0, 99, :, 0]\n",
    "\n",
    "nmodels = 6\n",
    "Index = [0,3,6, 9, 3, 6]\n",
    "for i in range(nmodels): \n",
    "  it0 = corrected_wide[i, Index[i], 0:1, :, 0]\n",
    "  it0p = Xo_val_w[i, Index[i], 0:1, :, 0]\n",
    "  it49 = corrected_wide[i, Index[i], 49:50, :, 0]\n",
    "  it49p = Xo_val_w[i, Index[i], 49:50, :, 0]\n",
    "  it99 = corrected_wide[i, Index[i], 99:100, :, 0]\n",
    "  it99p = Xo_val_w[i, Index[i], 99:100, :, 0]\n",
    "  if i == 0: \n",
    "    trace0 = it0\n",
    "    trace0p = it0p\n",
    "    trace49 = it49\n",
    "    trace49p = it49p\n",
    "    trace99 = it99\n",
    "    trace99p = it99p\n",
    "  else:\n",
    "    trace0 = np.append(trace0, it0, axis=0)\n",
    "    trace0p = np.append(trace0p, it0p, axis=0)\n",
    "    trace49 = np.append(trace49, it49, axis=0)\n",
    "    trace49p = np.append(trace49p, it49p, axis=0)\n",
    "    trace99 = np.append(trace99, it99, axis=0)\n",
    "    trace99p = np.append(trace99p, it99p, axis=0)\n",
    "\n",
    "\n",
    "fig1 = plt.figure(figsize=(30,7))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(reference_gather_1[0, 0, 0, :, 0], color='black', label=(\"Auxiliary Record\"))\n",
    "plt.plot(trace0p[0,:], color=colors[0], alpha=0.8,label=(\"-6.0% Instance\"))\n",
    "plt.plot(trace0p[1,:], color=colors[1],alpha=0.8, label=(\"-4.5% Instance\"))\n",
    "plt.plot(trace0p[4,:],color=colors[2], alpha=0.8,label=(\"-3.0% Instance\"))\n",
    "plt.plot(trace0p[5,:],color=colors[3], alpha=0.8,label=(\"+3.0% Instance\"))\n",
    "plt.plot(trace0p[2,:], color=colors[4],alpha=0.8, label=(\"+4.5% Instance\"))\n",
    "plt.plot(trace0p[3,:],color=colors[5], alpha=0.8,label=(\"+6.0% Instance\"))\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.title('Perturbed Far Offset (-3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(reference_gather_1[0, 0, 0, :, 0], color='black', label=(\"Auxiliary Record\"))\n",
    "plt.plot(trace0[0,:], color=colors[0], alpha=0.8,label=(\"-6.0% Instance\"))\n",
    "plt.plot(trace0[1,:], color=colors[1],alpha=0.8, label=(\"-4.5% Instance\"))\n",
    "plt.plot(trace0[4,:],color=colors[2], alpha=0.8,label=(\"-3.0% Instance\"))\n",
    "plt.plot(trace0[5,:],color=colors[3], alpha=0.8,label=(\"+3.0% Instance\"))\n",
    "plt.plot(trace0[2,:], color=colors[4],alpha=0.8, label=(\"+4.5% Instance\"))\n",
    "plt.plot(trace0[3,:],color=colors[5], alpha=0.8,label=(\"+6.0% Instance\"))\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.title('Redatumed Far Offset (-3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "fname = 'Trace 1'\n",
    "plt.savefig(fname)\n",
    "\n",
    "fig2 = plt.figure(figsize=(30,7))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(reference_gather_1[0, 0, 49, :, 0], color='black', label=(\"Reference\"))\n",
    "plt.plot(trace49p[0,:], color=colors[0], alpha=0.8, label=(\"Test 1\"))\n",
    "plt.plot(trace49p[1,:], color=colors[1], alpha=0.8, label=(\"Test 2\"))\n",
    "plt.plot(trace49p[2,:], color=colors[2], alpha=0.8,label=(\"Test 3\"))\n",
    "plt.plot(trace49p[3,:],color=colors[3],alpha=0.8, label=(\"Test 4\"))\n",
    "plt.plot(trace49p[4,:],color=colors[4], alpha=0.8, label=(\"Test 5\"))\n",
    "plt.plot(trace49p[5,:],color=colors[5], alpha=0.8,label=(\"Test 6\"))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Zero Offset', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(reference_gather_1[0, 0, 49, :, 0], color='black', label=(\"Reference\"))\n",
    "plt.plot(trace49[0,:], color=colors[0], alpha=0.8,label=(\"Test 1\"))\n",
    "plt.plot(trace49[1,:], color=colors[1], alpha=0.8,label=(\"Test 2\"))\n",
    "plt.plot(trace49[2,:], color=colors[2],alpha=0.8, label=(\"Test 3\"))\n",
    "plt.plot(trace49[3,:],color=colors[3], alpha=0.8,label=(\"Test 4\"))\n",
    "plt.plot(trace49[4,:],color=colors[4], alpha=0.8,label=(\"Test 5\"))\n",
    "plt.plot(trace49[5,:],color=colors[5], alpha=0.8,label=(\"Test 6\"))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Zero Offset', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "fname = 'Trace 50'\n",
    "#plt.savefig(fname)\n",
    "\n",
    "fig3 = plt.figure(figsize=(30,7))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.4)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(reference_gather_1[0, 0, 0, :, 0], color='black', label=(\"Reference\"))\n",
    "plt.plot(trace99p[0,:], color=colors[0], alpha=0.8,label=(\"Test 1\"))\n",
    "plt.plot(trace99p[1,:], color=colors[1], alpha=0.8,label=(\"Test 2\"))\n",
    "plt.plot(trace99p[2,:], color=colors[2], alpha=0.8,label=(\"Test 3\"))\n",
    "plt.plot(trace99p[3,:],color=colors[3], alpha=0.8,label=(\"Test 4\"))\n",
    "plt.plot(trace99p[4,:],color=colors[4], alpha=0.8,label=(\"Test 5\"))\n",
    "plt.plot(trace99p[5,:],color=colors[5], alpha=0.8,label=(\"Test 6\"))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Far Offset (+3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(reference_gather_1[0, 0, 0, :, 0], color='black', label=(\"Reference\"))\n",
    "plt.plot(trace99[0,:], color=colors[0], alpha=0.8,label=(\"Test 1\"))\n",
    "plt.plot(trace99[1,:], color=colors[1], alpha=0.8,label=(\"Test 2\"))\n",
    "plt.plot(trace99[2,:], color=colors[2], alpha=0.8,label=(\"Test 3\"))\n",
    "plt.plot(trace99[3,:],color=colors[3], alpha=0.8,label=(\"Test 4\"))\n",
    "plt.plot(trace99[4,:],color=colors[4], alpha=0.8,label=(\"Test 5\"))\n",
    "plt.plot(trace99[5,:],color=colors[5], alpha=0.8,label=(\"Test 6\"))\n",
    "plt.xlabel(\"Time (s)\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Standardized Waveform Amplitude\", fontsize=14, labelpad=15)\n",
    "plt.xticks(np.linspace(0, 560, 10), np.around(np.linspace(start=1.121, stop=8.84565, num=10), 3))\n",
    "plt.title('Far Offset (+3.25km)', fontsize=17, pad=8)\n",
    "plt.legend(fontsize=12)\n",
    "fname = 'Trace 100'\n",
    "#plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "SXkH5oXINbgL",
    "outputId": "b4188291-8ec7-4c6f-b0a5-35c55aa99ed8"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Plot uncorrected val gather and reference velocity gather side by side\n",
    "#Plot corrected/hybrid validation gather underneath and true reference validation gather. \n",
    "\n",
    "#Set flags - pick data point: Instance numbers\n",
    "time = np.linspace(start=1.121, stop=8.84565, num=560)\n",
    "plot_data_heatmap(Xo_val_ref_w[0,0,:,:,0] - corrected_wide[0,7,:,:,0])\n",
    "plot_wiggle(corrected_wide[0,7,:,:,0], t=time, label_flag='on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQURHEJYMS6J"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "ioRlFC0J0P8l",
    "outputId": "b79aa812-331e-4a50-e32e-a52f3ab40558"
   },
   "outputs": [],
   "source": [
    "#View Corrections\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Decide on format\n",
    "! pip install wiggle\n",
    "import wiggle\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Define plot_wiggle function\n",
    "def plot_wiggle(x,c='k', txt='none', t=None, label_flag='off'):\n",
    "    import numpy as np\n",
    "    import wiggle as wiggle\n",
    "    import matplotlib.pyplot as plt\n",
    "    # fig=plt.figure(dpi=150, figsize=(6,12))\n",
    "    sf=np.max(np.std(x,axis=1))\n",
    "    wiggle.wiggle(x.T, tt = t, color=c, sf= sf/0.5/10)#\n",
    "    # if(txt != 'none'):\n",
    "        # plt.text(0.5, 8, txt, size=20, color='black', bbox=dict(facecolor='red', alpha=1,))\n",
    "    plt.axis(label_flag)\n",
    "    # plt.savefig(os.path.join(dir,s), bbox_inches='tight')\n",
    "    # plt.close()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Plot uncorrected val gather and reference velocity gather side by side\n",
    "#Plot corrected/hybrid validation gather underneath and true reference validation gather. \n",
    "\n",
    "#Set flags - pick data point: Instance numbers\n",
    "instances = [0,1,2] #6,7,8\n",
    "time = np.linspace(start=1.121, stop=8.84565, num=560)\n",
    "time.shape #560\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Information about data\n",
    "ref_data = (ten_identical_ref_gathers[0, 5, :, :, 0]) #ten_identical_ref_gathers\n",
    "#tval_data = (reference_val_gather_1[0, 0, :, :, 0])\n",
    "pval_data_1 = (perturbed_val_gather_1[0, instances[0], :, :, 0])\n",
    "pval_data_2 = (perturbed_val_gather_1[0, instances[1], :, :, 0])\n",
    "pval_data_3 = (perturbed_val_gather_1[0, instances[2], :, :, 0])\n",
    "cval_data_1 = (corrected_val_gathers_1[0, instances[0], :, :, 0])\n",
    "cval_data_2 = (corrected_val_gathers_1[0, instances[1], :, :, 0])\n",
    "cval_data_3 = (corrected_val_gathers_1[0, instances[2], :, :, 0])\n",
    "val_water_pert_1 = round(labels_val[val_sample][str(instances[0])]['water_pertubation'], 3)\n",
    "val_water_pert_2 = round(labels_val[val_sample][str(instances[1])]['water_pertubation'], 3)\n",
    "val_water_pert_3 = round(labels_val[val_sample][str(instances[2])]['water_pertubation'], 3)\n",
    "\n",
    "#ID = labels_train[sample][str(instance)]['ID']\n",
    "#water_pert = round(labels_train[sample][str(instance)]['water_pertubation'], 3)\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Plot data\n",
    "fig1 = plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Auxiliary record', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(ref_data, 'b')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('True Validation Model', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(tval_data)\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "fname = 'Reference and True Validation Model'\n",
    "#plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "LxjWUE_101ta",
    "outputId": "de4aa6b7-5f84-4a3f-fb79-913a2ff000a2"
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(30,21))\n",
    "\n",
    "plt.subplot(3, 4, 1)\n",
    "plt.title(str(val_water_pert_1) +  '% ' 'Perturbed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(pval_data_1, t=time, label_flag='on')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(3,4,2)\n",
    "plt.title('Redatumed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(cval_data_1, 'b', t=time, label_flag='on')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(3, 4, 3)\n",
    "plt.title('Reference Validation - Redatumed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow(np.transpose(cval_data_1-tval_data), aspect='auto', cmap='RdBu', extent = [0, 100, 8.846, 1.121])\n",
    "#plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "#plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "plt.axis(\"On\")\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "\n",
    "plt.subplot(3, 4, 4)\n",
    "plt.title('Reference Validation - Perturbed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow(np.transpose(pval_data_1-tval_data), aspect='auto', cmap='RdBu', extent = [0, 100, 8.846, 1.121])\n",
    "#plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "#plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "plt.axis(\"On\")\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "\n",
    "plt.subplot(3, 4, 5)\n",
    "plt.title(str(val_water_pert_2) +  '% ' 'Perturbed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(pval_data_2, t=time, label_flag='on')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(3, 4, 6)\n",
    "plt.title('Redatumed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(cval_data_2, 'b', t=time, label_flag='on')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(3, 4, 7)\n",
    "plt.title('Reference Validation - Redatumed Validation', fontsize = 15, pad =12)\n",
    "#plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow(np.transpose(cval_data_2-tval_data), aspect='auto', cmap='RdBu', extent = [0, 100, 8.846, 1.121])\n",
    "plt.axis(\"On\")\n",
    "#plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "#plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "\n",
    "plt.subplot(3, 4, 8)\n",
    "plt.title('Reference Validation - Perturbed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow(np.transpose(pval_data_2-tval_data), aspect='auto', cmap='RdBu', extent = [0, 100, 8.846, 1.121])\n",
    "#plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "#plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "plt.axis(\"On\")\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "\n",
    "plt.subplot(3, 4, 9)\n",
    "plt.title(str(val_water_pert_3) +  '% ' 'Perturbed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(pval_data_3, t=time, label_flag='on')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(3, 4, 10)\n",
    "plt.title('Redatumed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plot_wiggle(cval_data_3, 'b', t=time, label_flag='on')\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "plt.subplot(3, 4, 11)\n",
    "plt.title('Reference Validation - Redatumed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow(np.transpose(cval_data_3-tval_data), aspect='auto', cmap='RdBu', extent = [0, 100, 8.846, 1.121])\n",
    "#plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "plt.axis(\"On\")\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "\n",
    "plt.subplot(3, 4, 12)\n",
    "plt.title('Reference Validation - Perturbed Validation', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow(np.transpose(pval_data_3-tval_data), aspect='auto', cmap='RdBu', extent = [0, 100, 8.846, 1.121])\n",
    "#plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "plt.axis(\"On\")\n",
    "cbar = plt.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "\n",
    "# plt.title('True Validation - Redatumed Validation', fontsize = 15, pad =12)\n",
    "# plt.tick_params(axis='both', labelsize=12)\n",
    "# plot_wiggle(tval_data-cval_data_3)\n",
    "# plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "# plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "\n",
    "\n",
    "fname = '66results.png'\n",
    "plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4MG5nEkc3Wb",
    "outputId": "7f08e9bd-0593-4b67-ae31-722116942d77"
   },
   "outputs": [],
   "source": [
    "#Evaluate norms\n",
    "from numpy import linalg as LA\n",
    "data1= cval_data_2\n",
    "data1 = np.transpose(data1)\n",
    "data2 = tval_data\n",
    "data2 = np.transpose(data2)\n",
    "num = data1-data2\n",
    "denom = data2\n",
    "\n",
    "num = LA.norm(num, 'fro')\n",
    "denom = LA.norm(denom, 'fro')\n",
    "data = num/denom\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnmxWA4G1Gn2"
   },
   "outputs": [],
   "source": [
    "def wiggle_superimpose(data1, \n",
    "                       data2,\n",
    "                      time,\n",
    "                      title=None,\n",
    "                      legend1 = 'Reference Model', \n",
    "                      legend2 = 'Perturbed Model',\n",
    "                      ax=None,\n",
    "                      skip=15,\n",
    "                      perc=99.0,\n",
    "                      gain=1.0,\n",
    "                      rgb=(1, 2, 3),\n",
    "                      alpha=1.0,\n",
    "                      lw=0.5,\n",
    "                      figsize=(16, 30),\n",
    "                      predict=False,\n",
    "                      save=True, \n",
    "                      fname= None):\n",
    "        \"\"\"\n",
    "        Plots wiggle traces of seismic data.\n",
    "        \n",
    "        Args:\n",
    "            data1 (ndarray): 2D seismic array. (reference model)\n",
    "            data2 (ndarray): 2D seismic array. (perturbed model)\n",
    "            time (ndarray): 1D seismic time array.\n",
    "            ax (Axes): matplotlib Axes object (optional).\n",
    "            skip (int): Skip=1, every trace, skip=2, every second trace, etc. #typically, skip = 15\n",
    "            perc (float): Percentile to scale to, default 99%.\n",
    "            gain (float): Gain value.\n",
    "            rgb (tuple): 3-tuple of RGB for the trace colour.\n",
    "            alpha (float): Opacity. Default 1.0.\n",
    "            lw (float): Lineweigth. Default 0.5.\n",
    "        Returns:\n",
    "            Axes: A matplotlib Axes object.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig = plt.figure(figsize=figsize) #default is (16,30)\n",
    "            ax = fig.add_subplot(111)\n",
    "        \n",
    "        receiverPos = np.arange(0,100,skip)\n",
    "        ntraces, nt = data1.shape\n",
    "        rgba = list(rgb) + [alpha]\n",
    "        sc1 = np.percentile(data1, perc)  # Normalization factor\n",
    "        wigdata1 = data1[::skip, :]\n",
    "        print (wigdata1.shape)\n",
    "        sc2 = np.percentile(data2, perc)  # Normalization factor\n",
    "        wigdata2 = data2[::skip, :]\n",
    "        xpos = np.arange(ntraces)[::skip]\n",
    "        \n",
    "        i = 0\n",
    "\n",
    "        for x, trace1, trace2 in zip(xpos, wigdata1, wigdata2):\n",
    "            # Compute high resolution trace.\n",
    "            amp1 = gain * trace1 / sc1 + x\n",
    "            amp2 = gain * trace2 / sc2 + x\n",
    "            t = 1000 * time\n",
    "            hypertime = np.linspace(t[0], t[-1], (10 * t.size - 1) + 1)\n",
    "            hyperamp1 = np.interp(hypertime, t, amp1)\n",
    "            hyperamp2 = np.interp(hypertime, t, amp2)\n",
    "            ax.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "            # Plot the line, then the fill.\n",
    "            if i==0:\n",
    "                ax.plot(hyperamp1, hypertime, 'k', lw=lw)\n",
    "                ax.fill_betweenx(hypertime, hyperamp1, x,\n",
    "                                 where=hyperamp1 > x,\n",
    "                                 facecolor='limegreen',\n",
    "                                 alpha=0.5,\n",
    "                                 lw=0,\n",
    "                                 label=legend1)\n",
    "                print ('ture')\n",
    "            else:\n",
    "                ax.plot(hyperamp1, hypertime, 'k', lw=lw)\n",
    "                ax.fill_betweenx(hypertime, hyperamp1, x,\n",
    "                                 where=hyperamp1 > x,\n",
    "                                 facecolor='limegreen',\n",
    "                                 alpha=0.5,\n",
    "                                 lw=0,\n",
    "                                 )\n",
    "            if i==0:  \n",
    "                ax.plot(hyperamp2, hypertime, 'k', lw=lw)\n",
    "                if predict: \n",
    "                    labelname = 'Predicted model'\n",
    "                else:\n",
    "                    labelname = legend2\n",
    "                ax.fill_betweenx(hypertime, hyperamp2, x,\n",
    "                                 where=hyperamp2 > x,\n",
    "                                 facecolor='orange',\n",
    "                                 alpha=0.5,\n",
    "                                 lw=0,\n",
    "                                 label=labelname)\n",
    "            else:\n",
    "                ax.plot(hyperamp2, hypertime, 'k', lw=lw)\n",
    "                ax.fill_betweenx(hypertime, hyperamp2, x,\n",
    "                                 where=hyperamp2 > x,\n",
    "                                 facecolor='orange',\n",
    "                                 alpha=0.5,\n",
    "                                 lw=0,\n",
    "                                )\n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "\n",
    "        ax.invert_yaxis()\n",
    "        l = plt.legend(prop={'size': 15})\n",
    "        if title!= None:\n",
    "            plt.title(title, fontsize = 15, pad =12)\n",
    "        else:\n",
    "            plt.title('Seismic Traces', fontsize = 15, pad =12)\n",
    "        plt.xlabel('Receiver number', fontsize = 15, labelpad = 10)\n",
    "        plt.xticks(receiverPos)\n",
    "        plt.ylabel('Time (milliseconds)', fontsize = 12, labelpad = 10)\n",
    "        plt.tight_layout()\n",
    "        if save:\n",
    "            plt.savefig(fname)\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b2RH_SeyFfPK",
    "outputId": "dc61fa47-51a6-48d5-c689-0ed08726c54c"
   },
   "outputs": [],
   "source": [
    "time = np.arange(0.001,6.601,0.012)\n",
    "data1 = tval_data\n",
    "data1 = np.transpose(data1)\n",
    "data2 = pval_data_1\n",
    "data2 = np.transpose(data2)\n",
    "title_line = \"Traces: True (Reference) Validation and Perturbed Data\" \n",
    "\n",
    "#fname = 'MIT Images/SYMAE/Variable Seafloor/Trace_difference_0001.08.png'\n",
    "plot = wiggle_superimpose(np.transpose(data1), np.transpose(data2), time, title=title_line, legend1='True Model', legend2='Perturbed Model', skip=5, figsize=(10,13), save=False, fname = fname)\n",
    "#plot.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "id": "zXiwUcGm3T9E",
    "outputId": "73bc8a73-ae02-4ea6-e4be-035a45610c46"
   },
   "outputs": [],
   "source": [
    "time = np.arange(0.001,6.601,0.012)\n",
    "data1 = tval_data\n",
    "data1 = np.transpose(data1)\n",
    "data2 = cval_data_1\n",
    "data2 = np.transpose(data2)\n",
    "title_line = \"Traces: True (Reference) Validation and Corrected Validation Data\" \n",
    "\n",
    "#fname = 'MIT Images/SYMAE/Variable Seafloor/Trace_difference_0001.08.png'\n",
    "plot = wiggle_superimpose(np.transpose(data1), np.transpose(data2), time, title=title_line, legend1='True Model', legend2='Corrected Model', skip=5, figsize=(10,13), save=False, fname = fname)\n",
    "#plot.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "id": "2iBa_5aC4bEq",
    "outputId": "8cc42aaa-c9dd-4494-f62b-a274007de1cc"
   },
   "outputs": [],
   "source": [
    "time = np.arange(0.001,6.601,0.012)\n",
    "data1 = pval_data_1\n",
    "data1 = np.transpose(data1)\n",
    "data2 = cval_data_1\n",
    "data2 = np.transpose(data2)\n",
    "title_line = \"Traces: Perturbed Validation and Corrected Validation Data\" \n",
    "\n",
    "#fname = 'MIT Images/SYMAE/Variable Seafloor/Trace_difference_0001.08.png'\n",
    "plot = wiggle_superimpose(np.transpose(data1), np.transpose(data2), time, title=title_line, legend1='Perturbed Model', legend2='Corrected Model', skip=5, figsize=(10,13), save=False, fname = fname)\n",
    "#plot.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "0q8-7a_C3jYM",
    "outputId": "629e4384-d112-4286-9c72-1940230e3314"
   },
   "outputs": [],
   "source": [
    "data1 = cval_data_1\n",
    "data1 = np.transpose(data1)\n",
    "data2 = tval_data\n",
    "data2 = np.transpose(data2)\n",
    "data = data1-data2\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Plot data\n",
    "fig1 = plt.figure(figsize=(8,8))\n",
    "plt.title('Perturbed - True, Model ' + str(901.08) +  '   (' + str(1.914) + '% pertubation)', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow((data), aspect='auto', cmap='RdBu', extent = [0, 100, 5896, 1250])\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "#fname = 'MIT Images/SYMAE/Variable Seafloor/Shot_gather_0001.00.png'\n",
    "#plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "Wxmfw6HOwP9Z",
    "outputId": "b78d2c73-57ac-43d9-e27a-b478de234622"
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "data1= pval_data_3\n",
    "data1 = np.transpose(data1)\n",
    "data2 = tval_data\n",
    "data2 = np.transpose(data2)\n",
    "num = data1-data2\n",
    "denom = data2\n",
    "\n",
    "num = LA.norm(num, 'fro')\n",
    "denom = LA.norm(denom, 'fro')\n",
    "data = num/denom\n",
    "print(data)\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "#Plot data\n",
    "fig1 = plt.figure(figsize=(8,8))\n",
    "plt.title('Perturbed - True, Model ' + str(901.08) +  '   (' + str(1.914) + '% pertubation)', fontsize = 15, pad =12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "im1 = plt.imshow((data), aspect='auto', cmap='RdBu', extent = [0, 100, 5896, 1250])\n",
    "plt.ylabel('Time (milliseconds)', fontsize = 15, labelpad = 10)\n",
    "plt.xlabel(\"Receiver number\", fontsize = 15, labelpad = 10)\n",
    "cbar = fig1.colorbar(im1)\n",
    "cbar.set_label('Waveform amplitude', fontsize = 15, labelpad=25, rotation=270)\n",
    "plt.clim(-5,5)\n",
    "#fname = 'MIT Images/SYMAE/Variable Seafloor/Shot_gather_0001.00.png'\n",
    "#plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wabsCrf4Zwm",
    "outputId": "da405e61-b24e-416e-f0b1-fb42dbdb5782"
   },
   "outputs": [],
   "source": [
    "! cp /content/drive/MyDrive/seismicTL_circular1_Brindha/plots.py .\n",
    "! pip install wiggle\n",
    "from plots import *\n",
    "\n",
    "def plot_seismic(X, labels, symencoder, nencoder, decoder):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import random \n",
    "    import wiggle\n",
    "    import tensorflow as tf\n",
    "    from datetime import datetime\n",
    "    from scipy import signal\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    now = datetime.now()\n",
    "    # dir = now.strftime(\"%d-%m-%Y_%H\")\n",
    "\n",
    "    # if not os.path.exists(dir): os.mkdir(dir)\n",
    "\n",
    "    nsamp=np.shape(X)[0]\n",
    "\n",
    "    plt.figure(figsize=(40,50), facecolor='w')\n",
    "\n",
    "\n",
    "    #i = np.random.randint(0, nsamp-1)\n",
    "    # j=random.choice([ii for ii in range(nsamp) if labels[ii][str(0)]['medium']!=labels[i][str(0)]['medium']])\n",
    "    # print(\"test_indices\"+str(i)+\",\"+str(j))\n",
    "\n",
    "    i=0\n",
    "    j=1\n",
    "\n",
    "    Gi=symencoder.predict(X[i:i+1]) #symmetric latent predictions from model 0, for all instances\n",
    "    Wi=nencoder.predict(X[i:i+1]) #nuisance latent predictions from model 0, for all instances\n",
    "\n",
    "    Zii=np.concatenate((Gi,Wi),axis=1) #concatenate those two predictions, for all instances, in the latent space\n",
    "\n",
    "    Xhatii=decoder.predict(Zii) #upsample with decoder from concatenated latent space\n",
    "\n",
    "    num_instance_plot = 5    #how many perturbations we are gonna look at\n",
    "    kki=random.choices(range(0,10),k=num_instance_plot) #pick 5 instances from the total instanecs -> ps: range excludes end index\n",
    "    for ikk,kk in enumerate(kki):    #for each instance number \n",
    "        ID = labels[i][str(kk)]['ID']\n",
    "        water_pert = round(labels_train[i][str(kk)]['water_pertubation'], 3)\n",
    "        plt.subplot(6, num_instance_plot, ikk+1) #horizontal spreading of plots over 1st row.\n",
    "        obs_data = X[i,kk,:,:,0]\n",
    "        plot_wiggle(obs_data)               #plotting input test data of that perturbation\n",
    "        plt.xticks([]); plt.yticks([]);\n",
    "        plt.title('Observed; Model ' + str(ID) +  '   (' + str(water_pert) + '% pertubation)' )\n",
    "        if ikk == 0:\n",
    "            plt.ylabel('Exact')\n",
    "                \n",
    "        plt.subplot(6, num_instance_plot, num_instance_plot+ikk+1) #horizontal spreading of plots over 2d row\n",
    "        prd_data = Xhatii[i,kk,:,:,0]\n",
    "        plot_wiggle(prd_data)                        #plotting decoded test data of perturbation\n",
    "        plt.xticks([]); plt.yticks([]);\n",
    "        plt.title('Predicted; Model ' + str(ID) +  '   (' + str(water_pert) + '% pertubation)')\n",
    "        if ikk == 0:\n",
    "            plt.ylabel('Predict')\n",
    "\n",
    "        plt.subplot(6, num_instance_plot, 2*num_instance_plot+ikk+1) #horizontal spreading of plots over 2d row\n",
    "        residual = prd_data-obs_data\n",
    "        plot_wiggle(residual)                        #plotting decoded test data of perturbation\n",
    "        plt.xticks([]); plt.yticks([]);\n",
    "        plt.title('Predicted-Observed; Model ' + str(ID) +  '   (' + str(water_pert) + '% pertubation)')\n",
    "        if ikk == 0:\n",
    "            plt.ylabel('Predict')\n",
    "\n",
    "        \n",
    "        \n",
    "    # Gj=symencoder.predict(X[j:j+1])\n",
    "    # Wj=nencoder.predict(X[j:j+1])\n",
    "    # Zjj=np.concatenate((Gj,Wj),axis=1)\n",
    "    # Zij=np.concatenate((Gi,Wj),axis=1)\n",
    "    # Zji=np.concatenate((Gj,Wi),axis=1)\n",
    "    # Xhatij=decoder.predict(Zij)\n",
    "    # Xhatjj=decoder.predict(Zjj)\n",
    "    # Xhatji=decoder.predict(Zji)\n",
    "    # for ikk, kk in enumerate(kki):\n",
    "    #     # style the jth bag with styles from the 0th bag\n",
    "    #     plt.subplot(6, num_instance_plot, 3*num_instance_plot+ikk+1)\n",
    "    #     a=Xhatji[0,kk,:,:,0]\n",
    "    #     plot_wiggle(a,'r')\n",
    "    #     plt.xticks([]); plt.yticks([]);\n",
    "\n",
    "    #     plt.subplot(6, num_instance_plot, 4*num_instance_plot+ikk+1)\n",
    "    #     b=X[j,kk,:,:,0]\n",
    "    #     plot_wiggle(b)\n",
    "    #     plt.xticks([]); plt.yticks([]);\n",
    "\n",
    "    #     plt.subplot(6, num_instance_plot, 5*num_instance_plot+ikk+1)\n",
    "    #     plot_wiggle(a-b)\n",
    "    #     plt.xticks([]); plt.yticks([]);\n",
    "    #     plt.title(str(mean_squared_error(a,b)))\n",
    "\n",
    "    plt.savefig('../predictions.png',dpi=400)               \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SjWQ8-p04Zwn",
    "outputId": "5300c9c0-5d4b-4c85-e7c6-4db704a75f32"
   },
   "outputs": [],
   "source": [
    "plot_seismic(Xo_test, labels_test,symencoder, nencoder, decoder)\n",
    "#plt.savefig('/content/drive/MyDrive/seismicTL_circular1_Brindha/predictions.png',dpi=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "Iy2NH8SC4Zwo",
    "outputId": "8546a582-df40-482e-aaf8-a4f115cb8a6b"
   },
   "outputs": [],
   "source": [
    "\n",
    "labelindices={'base0': [], 'moni1' : [], 'moni2' : []}\n",
    "for (i,label) in enumerate(labels):\n",
    "    labelindices[label[0][0]].append(i)\n",
    "\n",
    "\n",
    "# In[281]:\n",
    "\n",
    "\n",
    "labels[labelindices['moni2']][0][0]\n",
    "\n",
    "\n",
    "# # Visualize Latent Space\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "# visualizing latent space\n",
    "\n",
    "\"\"\"\n",
    "fig=plt.figure(dpi=100, figsize=(15,8))\n",
    "for label in ['100', '200', '300', '400', '500']:\n",
    "    i = labelindices[label][0:1]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        latentsr=encoderr(Xo[i])\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "with tf.device('/gpu'):\n",
    "    test_large_indices = [np.random.randint(1, nsamp) for i in range(0,64)]\n",
    "    latentsT=nencoder.predict(Xo_train                           [test_large_indices])\n",
    "    latentsr=symencoder.predict(Xo_train[test_large_indices])\n",
    "    #print(np.shape(latentsr))\n",
    "    fig, axs = plt.subplots(2, 2, dpi=100, figsize=(15,8))\n",
    "    a=axs[0,0].imshow(latentsr, aspect=1)\n",
    "    #for l in latentsr:\n",
    "    #    a=axs[0,0].plot(l)\n",
    "    axs[0,0].set_title('G')\n",
    "    plt.colorbar(a, ax=axs[0,0]) \n",
    "\n",
    "    #a=axs[1,0].imshow(tf.exp(latentsr[1]), aspect=1)\n",
    "    #axs[1,0].set_title('sigma encoderr output for samples')\n",
    "    #plt.colorbar(a, ax=axs[1,0]) \n",
    "\n",
    "    b=axs[0,1].imshow(latentsT, aspect=1)\n",
    "    axs[0,1].set_title('Z')\n",
    "    plt.colorbar(b, ax=axs[0,1]) \n",
    "    \n",
    "plt.gcf()\n",
    "#b=axs[1,1].imshow(tf.exp(latentsT[1]), aspect=1)\n",
    "#axs[1,1].set_title('sigma encoderT output for samples')\n",
    "#plt.colorbar(b, ax=axs[1,1]) \n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "plt.imshow(latentsT)\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "with tf.device('/gpu'):\n",
    "    latentsr={'base0': [], 'moni1':[],'moni2':[]}\n",
    "    for label in ['base0', 'moni1', 'moni2']:\n",
    "        i = labelindices[label][1:20]\n",
    "        with tf.device('/gpu:0'):\n",
    "            latentsr[label]=symencoder.predict(Xo_train[i])\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,5,dpi=500, figsize=(3,2))\n",
    "markers=['r', 'b', 'c', 'g', 'm']\n",
    "subs=['(a)', '(b)', '(c)', '(d)', '(e)']\n",
    "for (i,label) in enumerate(['base0', 'moni1', 'moni2', 'base0', 'base0']):\n",
    "    lmean=np.mean(latentsr[label], axis=0)\n",
    "    #ax[i].plot(lmean, color='k', linewidth=0.1)\n",
    "    ax[1,i].imshow(latentsr[label].T)\n",
    "    # Hide grid lines\n",
    "    ax[1,i].grid(False)\n",
    "#     Hide axes ticks\n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "    ax[1,i].set_xlabel('$\\tau$')\n",
    "    ax[1,i].set_ylabel('$Z_g$')\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax[0,i].imshow(vp[label].T, cmap='RdBu')\n",
    "    ax[0,i].axis('off')\n",
    "    ax[0,i].set_xlabel('$x$')\n",
    "    ax[0,i].set_ylabel('$z$')\n",
    "    ax[0,i].set_title(subs[i]+'$\\epsilon=$'+str(i))\n",
    "\n",
    "\n",
    "    #for l in latentsr[label]:\n",
    "     #   ax[i].fill_between(range(0,96), l, lmean, color=markers[i], alpha=0.1)\n",
    "        #ax[i].set_xlabel()\n",
    "        \n",
    "plt.gcf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7-3Urg64Zwp"
   },
   "outputs": [],
   "source": [
    "#TO tRAIN \n",
    "\n",
    "batch_size=2\n",
    "ds_train=tf.data.Dataset.from_tensor_slices((Xo_train, Xo_train))\n",
    "ds_train = ds_train.shuffle(nsamp,reshuffle_each_iteration=True) \n",
    "ds_train=ds_train.batch(batch_size)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test=tf.data.Dataset.from_tensor_slices((Xo_test, Xo_test))\n",
    "ds_test=ds_test.batch(batch_size)\n",
    "history=model.fit(ds_train,epochs=50,  shuffle=True, validation_data=ds_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "v1_reproducibility.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
