{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24895169-9c60-4377-944b-1fb5e7d22527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 23:46:23.278628: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85fc3286-8ade-457b-8570-e982e2393644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, 1, 'same', name='conv1')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization(name='bn1',\n",
    "                                    activity_regularizer=tf.keras.regularizers.L2(0.01))\n",
    "        self.d1 = tf.keras.layers.Dense(5, activation='elu', name='d1')\n",
    "        self.d2 = tf.keras.layers.Dense(5, name='d2')\n",
    "    def call(self, x):\n",
    "        #x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.d1(x)\n",
    "        #x = self.d2(x)\n",
    "        return x\n",
    "    def my_summary(self):\n",
    "        x = tf.keras.layers.Input(shape=(5), name='input')\n",
    "        return tf.keras.Model(inputs=x, outputs=self.call(x), name='model').summary()\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73e3e366-9aa5-4585-8e1d-8e78a144f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 5)]               0         \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 5)                 20        \n",
      "                                                                 \n",
      " d1 (Dense)                  (None, 5)                 30        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 40\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.my_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c428e135-954b-430e-b2c2-f905e28334de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,4,5]]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5c3c117-a655-4a05-9682-f7e6df9f8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 499, loss is 0.025048.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a0c1ceca0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        clear_output(wait=True)\n",
    "        print(\"For epoch {:d}, loss is {:f}.\".format(epoch, logs[\"loss\"]))\n",
    "model.fit(X, X, epochs=500, verbose=0, callbacks=CustomCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "601bc66c-e5a5-435b-8d0a-593ec2ed77e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ],\n",
       "       [0.9999999, 2.       , 2.9999995, 3.9999998, 5.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d0c9a3-a869-450a-9af6-ec8cb4cc0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b148c6-db8e-4d89-b255-2202c4976773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 20, 10), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt=20\n",
    "q=10\n",
    "out=tf.constant([1.0]*1000)\n",
    "out=tf.reshape(out, [-1, nt, q])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d77bc5e2-18d2-4758-b8d6-7acc1743a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import symae_core as symae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0be01d8d-1c5c-4339-aecb-c7b32d40ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_enc_input = tfk.Input(shape=(nt, d), dtype='float32', name='sym_enc_input')\n",
    "sym_enc_output = symae.SymmetricEncoderDense1D(p, d, [2, 2, 2])(sym_enc_input)\n",
    "sym_encoder = tfk.Model(sym_enc_input, sym_enc_output, name='sym_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aba35a80-e5be-4f58-81d5-4622504939ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sym_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sym_enc_input (InputLayer)  [(None, 20, 100)]         0         \n",
      "                                                                 \n",
      "  (SymmetricEncoderDense1D)  (None, 3)                 13053     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,053\n",
      "Trainable params: 12,953\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sym_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3585a-e1c6-4626-a479-7991ae4a8eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
