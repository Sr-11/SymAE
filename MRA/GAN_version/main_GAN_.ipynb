{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142c52d0-d442-4c3d-94a7-40d6eb980d3e",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be32a819-ee3d-4992-85c8-e25c20df77d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b6b0f5-36ce-435e-9af6-b9394bdff7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime\n",
    "from scipy.stats import linregress\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import trange, tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfkltd= tf.keras.layers.TimeDistributed\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de24bc6-53dd-4662-848e-172b1c5cccd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import custom packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd50e50c-cd4a-4bce-bbbd-52c40895575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "TensorFlow Version:  2.9.1\n"
     ]
    }
   ],
   "source": [
    "from MRA_generate import MRA_generate\n",
    "from symae_model import SymAE\n",
    "from parameters import *\n",
    "from redatuming import redatuming\n",
    "from latent import latent\n",
    "from plot_training import plot_training\n",
    "from plot_redatuming import plot_redatuming\n",
    "from plot_save import plot_save\n",
    "import symae_core as symae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b52c2b-7f7c-420a-b90e-0911dc098204",
   "metadata": {},
   "source": [
    "# Creat D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0522272-63e5-44ce-87ba-8e38f6a582ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = 7\n",
    "nl = d\n",
    "D = np.empty((ne,nl,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57920df3-317f-4620-9d30-56f582c25483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(n,x):\n",
    "    if n==0:\n",
    "        return math.e**(-5*(x-0.5)**2)\n",
    "    elif n==1:\n",
    "        return math.e**(-10*(x-0.5)**2)\n",
    "    elif n==2:\n",
    "        if x<0.3:\n",
    "            return 3*x\n",
    "        elif x<0.6:\n",
    "            return 3*(0.6-x)\n",
    "        else:\n",
    "            return 0\n",
    "    elif n==3:\n",
    "        return int(x<0.5)\n",
    "    elif n==4:\n",
    "        return math.e**(-30*(x-0.5)**2)\n",
    "    elif n==5:\n",
    "        return math.cos(2*math.pi*x)\n",
    "    elif n==6:\n",
    "        return math.e**(-9*x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12b4796-455f-4a6a-973c-5738f50a4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ne):\n",
    "    theta = np.array([g(i,k/d) for k in range(d)])\n",
    "    for j in range(nl):\n",
    "        D[i,j,:] = np.roll(theta, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0d5738-beb1-41f6-909f-2088c167e38d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnx\u001b[49m):\n\u001b[1;32m      2\u001b[0m     e \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(n1))\n\u001b[1;32m      3\u001b[0m     X_states[i] \u001b[38;5;241m=\u001b[39m e\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(nx):\n",
    "    e = np.random.choice(range(n1))\n",
    "    X_states[i] = e\n",
    "    for t in range(nt):\n",
    "        c = np.random.randint(0,n2)\n",
    "        X_nuisances[i,t] = c\n",
    "        X[i,t,0] = D[e,c]        \n",
    "        selected_times[e,c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53947e26-7893-460b-88c5-d9cba2316a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bb053-92ed-4a2f-8ca4-2afbc4b26b72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf99139-62f2-4608-bffe-64b1cc6e4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_encoder = symae.SymmetricEncoderDense1D(p, d, [2, 2, 2]) #(N,nt,d)->(N,p)\n",
    "nui_encoder = symae.NuisanceEncoderDense1D(q, d, [2, 2, 2]) #(N,nt,d)->(N,nt,q)\n",
    "latentcat=symae.LatentCat(dropout_rate) #(N,p),(N,nt*q)->(N,p+nt*q)\n",
    "distzsym = symae.DistributeZsym(nt, p, q) #(N,p+q*nt)->(N,nt,p+q)\n",
    "mix_decoder = symae.MixerDense1D(d, p+q) #(N,nt,p+q)->(N,nt,d)\n",
    "class discriminator(tf.keras.Model): #(N,nt,p+q)->True/False\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__(name='')\n",
    "        self.d1 = tfkltd(tfkl.Dense(100, activation=tf.keras.layers.LeakyReLU(0.2)))\n",
    "        self.d2 = tfkltd(tfkl.Dense(100, activation=tf.keras.layers.LeakyReLU(0.2)))\n",
    "        self.d3 = tfkltd(tfkl.Dense(100, activation=tf.keras.layers.LeakyReLU(0.2)))\n",
    "        self.d4 = tfkltd(tfkl.Dense(100, activation=tf.keras.layers.LeakyReLU(0.2)))\n",
    "        self.d5 = tfkltd(tfkl.Dense(1))\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        x = self.d4(x)\n",
    "        x = self.d5(x)\n",
    "        return x\n",
    "discriminator = discriminator() #(N,nt,p+q)->True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c29d884-cd53-4910-95d2-a18b3eb57e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_encoder._name = 'sym_encoder'\n",
    "nui_encoder._name = 'nui_encoder'\n",
    "latentcat._name = 'latentcat'\n",
    "distzsym._name = 'distzsym'\n",
    "mix_decoder._name = 'mix_decoder'\n",
    "discriminator._name = 'discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5c76d-1999-4806-bae7-7ca7819c6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "symae_input = tfk.Input(shape=(nt,d))\n",
    "sym_out = sym_encoder(symae_input)\n",
    "sym_repeat = tfkl.RepeatVector(nt)(sym_out)\n",
    "\n",
    "nui_out = nui_encoder(symae_input)\n",
    "dec_input = tf.concat([sym_repeat, nui_out], axis=2)\n",
    "symae_output = mix_decoder(dec_input)\n",
    "\n",
    "ae = tfk.Model(symae_input,symae_output, name=\"SymAE\") \n",
    "encoder = tfk.Model(symae_input,dec_input, name=\"encoder\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122166e5-f7b8-47ca-a92b-5e7807df62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all():\n",
    "    encoder.save_weights('gan_test/e')\n",
    "    mix_decoder.save_weights('gan_test/g')\n",
    "    discriminator.save_weights('gan_test/d')\n",
    "def load_all():\n",
    "    encoder.load_weights('gan_test/e')\n",
    "    mix_decoder.load_weights('gan_test/g')\n",
    "    discriminator.load_weights('gan_test/d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901651e9-642c-47b8-b5fb-da4ccf629b34",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222a911-3810-4060-af02-2876d0f09c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_c = tf.keras.optimizers.Adam(0.001)\n",
    "optimizer_d = tf.keras.optimizers.Adam(0.001)\n",
    "optimizer_n =tf.keras.optimizers.Adam(0.0001)\n",
    "optimizer_m =tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1658a2-65d9-4d45-8002-f858f15cc26d",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9590316-a8e4-4a3c-9e20-0f5598bd1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def adversarial_loss():\n",
    "    H = encoder(D)\n",
    "    S = 0.0\n",
    "    for i in range(ne):\n",
    "        for j in range(ne):\n",
    "            if j==i:\n",
    "                continue\n",
    "            merger = tf.concat([  H[j,0,0:p], tf.reshape(H[i,:,p:p+q], [-1])], \n",
    "                               axis=0)\n",
    "            merger = tf.expand_dims(merger, axis=0)\n",
    "            merger = tf.expand_dims(merger, axis=0)\n",
    "\n",
    "            fake_out = discriminator(merger)\n",
    "            fake_loss = cross_entropy(tf.ones_like(fake_out), fake_out)\n",
    "            S += fake_loss\n",
    "    S /= (ne**2-ne)\n",
    "    return S\n",
    "\n",
    "def discriminator_loss():\n",
    "    H = encoder(D)\n",
    "    S = 0.0\n",
    "    for i in range(ne):\n",
    "        for j in range(ne):\n",
    "            if j==i:\n",
    "                continue\n",
    "            latent_code_real = tf.concat([  H[i,0,0:p], tf.reshape(H[i,:,p:p+q], [-1])  ], \n",
    "                                         axis=0)\n",
    "            latent_code_real = tf.expand_dims(latent_code_real, axis=0)\n",
    "            latent_code_real = tf.expand_dims(latent_code_real, axis=0)\n",
    "\n",
    "            merger = tf.concat([  H[j,0,0:p], tf.reshape(H[i,:,p:p+q], [-1])], \n",
    "                               axis=0)\n",
    "            merger = tf.expand_dims(merger, axis=0)\n",
    "            merger = tf.expand_dims(merger, axis=0)\n",
    "\n",
    "            real_out = discriminator(latent_code_real)\n",
    "            fake_out = discriminator(merger)\n",
    "            real_loss = cross_entropy(tf.ones_like(real_out), real_out)\n",
    "            fake_loss = cross_entropy(tf.zeros_like(fake_out), fake_out)\n",
    "            S += real_loss + fake_loss\n",
    "    #tf.print(fake_loss)\n",
    "    S /= (ne**2-ne)\n",
    "    return S\n",
    "\n",
    "@tf.function\n",
    "def redatuming_loss():\n",
    "    H = encoder(D)\n",
    "    S = 0.0\n",
    "    merger_list = []\n",
    "    real_out_list = []\n",
    "    for i in range(ne):\n",
    "        for j in range(ne):\n",
    "            if j==i:\n",
    "                continue\n",
    "            merger = tf.concat([H[i,:,0:p], H[j,:,p:p+q]], axis=1)\n",
    "            merger_list.append(merger)\n",
    "            real_out_list.append(D[i,:,:])\n",
    "    redatum = mix_decoder(tf.stack(merger_list))\n",
    "    synthetic = tf.stack(real_out_list)\n",
    "    return mse(redatum,synthetic)\n",
    "'''\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape_ae, tf.GradientTape() as tape_D, tf.GradientTape() as tape_N:\n",
    "        rec_loss = mse(D, ae(D))\n",
    "        adver_loss = adversarial_loss()\n",
    "        disc_loss = discriminator_loss()\n",
    "        #disc_loss = real_loss + fake_loss\n",
    "        ae_loss = rec_loss\n",
    "        N_loss = adver_loss\n",
    "        D_loss = disc_loss\n",
    "    ae_gradients = tape_ae.gradient(ae_loss, ae.trainable_variables)\n",
    "    D_gradients = tape_D.gradient(D_loss, discriminator.trainable_variables)\n",
    "    optimizer_ae.apply_gradients(zip(ae_gradients, ae.trainable_variables))\n",
    "    optimizer_disc.apply_gradients(zip(D_gradients, discriminator.trainable_variables))\n",
    "    #if epoch%10==0:\n",
    "    N_gradients = tape_N.gradient(N_loss, nui_encoder.trainable_variables)\n",
    "    optimizer_n.apply_gradients(zip(N_gradients, nui_encoder.trainable_variables))\n",
    "    return rec_loss, disc_loss, adver_loss #, real_loss, fake_loss\n",
    "'''\n",
    "\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape_c, tf.GradientTape() as tape_n, tf.GradientTape() as tape_d, tf.GradientTape() as tape_m:\n",
    "        rec_loss = mse(D, ae(D))\n",
    "        adver_loss = adversarial_loss()\n",
    "        disc_loss = discriminator_loss()\n",
    "        #disc_loss = real_loss + fake_loss\n",
    "        c_loss = rec_loss\n",
    "        n_loss = rec_loss + 0.001*adver_loss\n",
    "        d_loss = disc_loss\n",
    "        m_loss = rec_loss\n",
    "    c_gradients = tape_c.gradient(c_loss, sym_encoder.trainable_variables)\n",
    "    n_gradients = tape_n.gradient(n_loss, nui_encoder.trainable_variables)\n",
    "    d_gradients = tape_d.gradient(d_loss, discriminator.trainable_variables)\n",
    "    m_gradients = tape_m.gradient(m_loss, mix_decoder.trainable_variables)\n",
    "    \n",
    "    optimizer_c.apply_gradients(zip(c_gradients, sym_encoder.trainable_variables))\n",
    "    optimizer_n.apply_gradients(zip(n_gradients, nui_encoder.trainable_variables))\n",
    "    optimizer_d.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n",
    "    optimizer_m.apply_gradients(zip(m_gradients, mix_decoder.trainable_variables))\n",
    "    return rec_loss, disc_loss, adver_loss #, real_loss, fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4f90b-ddf0-4d5d-8a4a-258809dc4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97c9cf-6b1e-45af-848e-da2ce3b7d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100000):\n",
    "    rec_loss, disc_loss, adver_loss = train_step()\n",
    "    redatum_loss = redatuming_loss()\n",
    "    print(\"===== epoch {:d} =====\".format(epoch))    \n",
    "    print(\"rec_loss:     {:f}\".format(rec_loss))\n",
    "    print(\"adver_loss:   {:f}\".format(adver_loss))\n",
    "    print(\"disc_loss:    {:f}\".format(disc_loss))        \n",
    "    print(\"redatum_loss: {:f}\".format(redatum_loss))        \n",
    "    clear_output(wait=True)\n",
    "    if epoch%1000==0:\n",
    "        save_all()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ba5c7-8630-4c66-92c0-1c51372649c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_loss, disc_loss, adver_loss = train_step()\n",
    "redatuming_loss()\n",
    "print(\"===== epoch {:d} =====\".format(epoch))    \n",
    "print(\"rec_loss:     {:f}\".format(rec_loss))\n",
    "print(\"adver_loss:   {:f}\".format(adver_loss))\n",
    "print(\"disc_loss:    {:f}\".format(disc_loss))        \n",
    "print(\"redatum_loss: {:f}\".format(redatum_loss))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6c3e1-f83e-4e7f-9fae-ac422ecb0757",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f923375-bf69-46dd-a290-f247ecb0207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('./checkpoint/'+datetime.now().strftime(\"%B%d\"))\n",
    "#model.save_weights('./checkpoint/'+'p=%d,q=%d,predata'%(p,q))\n",
    "print(\"weights saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fbf56-4c23-4e13-b154-8d2c45186f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "462e4883-c204-43d9-8418-5f9fce087660",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Redatuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb03a24-731a-4e8d-af04-37e3bb3c0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = encoder(D)\n",
    "def redatum(s1,s2,l1,l2):\n",
    "    code_state1 = H[s1, l1, 0:p].numpy()\n",
    "    code_shift2 = H[s2, l2, p:p+q].numpy()\n",
    "    latent_code = np.concatenate([code_state1, code_shift2])\n",
    "    latent_code = latent_code[np.newaxis, np.newaxis, :]\n",
    "    redatum = mix_decoder(latent_code)\n",
    "    return redatum[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d4013-5068-42de-b069-5ba910b41f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0\n",
    "s2 = 0\n",
    "l1 = 0\n",
    "l2 = 0\n",
    "plt.plot(range(d), redatum(s1,s2,l1,l2), label='redatum')\n",
    "#plt.plot(range(d), [g(s1,(k+l2)%d/d) for k in range(d)], label='origin')\n",
    "plt.plot(range(d), D[s1,l2], label='D')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1603ccd-7275-48d8-a0d9-805edc0f80b6",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedbd55-0c90-4aea-90e6-6bea5296eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = encoder(D)\n",
    "N = H[:,:,p:p+q]\n",
    "N_reshaped = np.reshape(N, [-1, q])\n",
    "N_reshaped = PCA(3).fit_transform(N_reshaped)\n",
    "state_reshaped = np.repeat(range(ne),d)[:,np.newaxis]\n",
    "shift_reshaped = np.array(list(range(d))*ne)[:,np.newaxis]\n",
    "tem = np.concatenate([N_reshaped,state_reshaped,shift_reshaped], axis=1)\n",
    "px.scatter_3d(pd.DataFrame(tem),x=0,y=1,z=2,color=3,title='q-space')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e25c2-10cd-40b8-93bb-d1c3ad2d2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.empty((ne,d,p))\n",
    "for i in trange(ne):\n",
    "    for j in range(d):\n",
    "        DD = D[i:i+1,j:j+1,:]\n",
    "        DD = np.tile(DD,[1,nt,1])\n",
    "        H[i,j,:] = (encoder(DD).numpy())[0,0,0:p]\n",
    "C = H[:,:,0:p]\n",
    "C_reshaped = PCA(3).fit_transform(np.reshape(C, [-1, p]))\n",
    "state_reshaped = np.repeat(range(ne),d)[:,np.newaxis]\n",
    "shift_reshaped = np.array(list(range(d))*ne)[:,np.newaxis]\n",
    "tem = np.concatenate([C_reshaped,state_reshaped,shift_reshaped], axis=1)\n",
    "px.scatter_3d(pd.DataFrame(tem),x=0,y=1,z=2,color=3,title='p-space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3a59e-7554-47c3-a766-4ce920a9bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = encoder(D)\n",
    "C = H[:,:,0:p]\n",
    "C_reshaped = PCA(3).fit_transform(np.reshape(C, [-1, p]))\n",
    "state_reshaped = np.repeat(range(ne),d)[:,np.newaxis]\n",
    "shift_reshaped = np.array(list(range(d))*ne)[:,np.newaxis]\n",
    "tem = np.concatenate([C_reshaped,state_reshaped,shift_reshaped], axis=1)\n",
    "px.scatter_3d(pd.DataFrame(tem),x=0,y=1,z=2,color=3,title='p-space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77213e6-55c1-4f63-9cf2-f6d47da040e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fadff9b-6233-4afe-bd5b-2e55154338ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### List many redatuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ca1d6-980f-4f53-a2e1-87a54019917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec(latent_code):\n",
    "    tem = latent_code[np.newaxis, np.newaxis, :]\n",
    "    tem = np.repeat(tem, nt, axis=1)\n",
    "    tem = model.mixer.predict(tem, verbose=0)\n",
    "    return tem[0,0,:]\n",
    "def enc(state, shift):\n",
    "    tem = np.array( [g(state, ((k+shift)%d)/d) for k in range(d)] )\n",
    "    tem = tem[np.newaxis, np.newaxis, :, np.newaxis]\n",
    "    tem = np.repeat(tem, nt, axis=1)\n",
    "    tem = model.encoder.predict(tem, verbose=0)\n",
    "    return tem[0][0:p+q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1399151-ed42-4d13-8f7d-180fbb492d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_source = 0\n",
    "nuisance_source = 40\n",
    "fig, axs = plt.subplots(1, d, sharex=True, sharey=True, figsize=(4*d,4), dpi=40)\n",
    "for i in trange(d):\n",
    "    coherent_code = enc(state_source, 0)[0: p]\n",
    "    nuisance_code = enc(nuisance_source, i)[p: p+q]\n",
    "    latent_code = np.concatenate([coherent_code, nuisance_code], axis=0)\n",
    "    axs[i].plot(range(d), dec(latent_code))\n",
    "    axs[i].set_title('%d'%i)\n",
    "plt.suptitle('$\\hat{X}_{s=%d \\mapsto s=%d}$'%(nuisance_source, state_source), fontsize=50)\n",
    "plt.subplots_adjust(top=0.6)\n",
    "plt.show()\n",
    "#fig.savefig('./plots/%dto%d'%(nuisance_source, state_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27b26c-d23f-42f5-9f32-49e66bda6c42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e56385-4c7a-43da-8358-a053cd8caad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec(latent_code):\n",
    "    tem = latent_code[np.newaxis, np.newaxis, :]\n",
    "    tem = np.repeat(tem, nt, axis=1)\n",
    "    tem = model.mixer.predict(tem, verbose=0)\n",
    "    return tem[0,0,:]\n",
    "def enc(state, shift):\n",
    "    tem = np.array( [g(state, ((k+shift)%d)/d) for k in range(d)] )\n",
    "    tem = tem[np.newaxis, np.newaxis, :, np.newaxis]\n",
    "    tem = np.repeat(tem, nt, axis=1)\n",
    "    tem = model.encoder.predict(tem, verbose=0)\n",
    "    return tem[0][0:p+q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0d3bb-3a8f-4cee-bad2-13ad49fa2d5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Set endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42bbca-f3de-4957-a8ed-65efb3e5992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = -1\n",
    "shift1 = 0\n",
    "shift2 = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae32fe-abe6-4b94-9207-5ec15f105184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(n,x):\n",
    "    if n==-1:\n",
    "        return int(x<0.5)\n",
    "    return np.exp(-math.sqrt(n+1)*(x-0.5)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802db79a-98f8-4d44-a35f-1a645536ea1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28ac42-db74-43f4-a467-b7ea66bc2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_number = L = 10\n",
    "interpolation = np.empty((L,d))\n",
    "for i, alpha in enumerate(range(L)):\n",
    "    alpha = alpha / L\n",
    "    code1 = enc(state, shift1)\n",
    "    code2 = enc(state, shift2)\n",
    "    code = alpha*code1 + (1-alpha)*code2\n",
    "    interpolation[i:i+1,:] = dec(code).T\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for i, alpha in enumerate(range(L)):\n",
    "    alpha = alpha / L\n",
    "    plt.plot(range(d),interpolation[i,:], color=(alpha,0,1-alpha))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e0953-26a7-47fe-8f26-7e6fe4571820",
   "metadata": {},
   "source": [
    "### Cubic Spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc8629-baa6-466a-9990-cd0a4c9fe31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spline():\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "        self.x = np.arange(0, d, 1)\n",
    "        self.y = np.empty((q, len(self.x)))\n",
    "        self.tck = []\n",
    "        self.center = enc(state, 0)[0:p]\n",
    "        for j in trange(len(self.x)):\n",
    "            l = self.x[j]\n",
    "            latent_code = enc(state, l)\n",
    "            for i in range(q):\n",
    "                self.y[i,j] = latent_code[p+i]\n",
    "        for i in range(q):\n",
    "            self.tck.append(interpolate.splrep(self.x, self.y[i,:], per=True))\n",
    "    def call(self, shift):\n",
    "        return np.array([interpolate.splev(shift, self.tck[i], der=0) for i in range(q)])\n",
    "    def call_batch(self, shifts):\n",
    "        return np.array([[interpolate.splev(shift, self.tck[i], der=0) for i in range(q)] for shift in shifts])\n",
    "    def decode(self, shift):\n",
    "        return dec(np.hstack([self.center, self.call(shift)]))\n",
    "    def decode_batch(self, shifts):\n",
    "        return np.array([self.decode(shift) for shift in tqdm(shifts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b6c3c-b728-41b1-bb0f-5854e6c0d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_obj = spline(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba1175-5715-4bb2-843e-1a3594e34684",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_obj.decode_batch([5,6]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7dbd7-0a7b-4083-b7c8-b9dfa035ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(d), spline_obj.decode(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25efec-66a2-46e8-ab17-b9783c6ac220",
   "metadata": {
    "tags": []
   },
   "source": [
    "### By hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d6216-d73d-494e-94c0-1043a93dbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code1 = enc(state, shift1)\n",
    "code2 = enc(state, shift2)\n",
    "code = 0.5*code1 + 0.5*code2 + 1.0\n",
    "interpolation = dec(code)\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(range(d), [g(state, ((k+shift1)%d)/d) for k in range(d)], color=(1,0,0))\n",
    "plt.plot(range(d), [g(state, ((k+shift2)%d)/d) for k in range(d)], color=(0,0,1))\n",
    "plt.plot(range(d),interpolation, color=(1,0,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8caf59d-76f5-4338-89bc-60fcfc29152d",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85891b-e64e-4d60-a9ea-52e226ba281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)\n",
    "Ns = np.empty((100,q))\n",
    "for i in trange(100):\n",
    "    shift = i\n",
    "    Ns[i,:] = enc(state, shift)[p:p+q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1018ba4-bcfc-4418-bdd9-b521febc4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_N = pca.fit_transform(Ns)\n",
    "pca_N1 = pca.transform(code1[np.newaxis, p:p+q])\n",
    "pca_N2 = pca.transform(code2[np.newaxis, p:p+q])\n",
    "pca_N_hand = pca.transform(code[np.newaxis, p:p+q])\n",
    "pca_N_spline = pca.transform(spline_obj.call_batch(np.arange(0,100,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa7a97-22db-4fe3-9acb-7fc8638dd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = go.Scatter(x=pca_N[:,0], y=pca_N[:,1], mode='markers', name='dataset')\n",
    "data1 = go.Scatter(x=pca_N1[:,0], y=pca_N1[:,1], mode='markers', marker=dict(color='rgb(255, 0, 0)'), name='endpoint1')\n",
    "data2 = go.Scatter(x=pca_N2[:,0], y=pca_N2[:,1], mode='markers', marker=dict(color='rgb(255, 0, 0)'), name='endpoint2')\n",
    "data_line = go.Scatter(x=[pca_N1[0,0],pca_N2[0,0]], y=[pca_N1[0,1],pca_N2[0,1]], marker=dict(color='rgb(255, 200, 0)'), name='line')\n",
    "data_hand = go.Scatter(x=pca_N_hand[:,0], y=pca_N_hand[:,1], mode='markers', marker=dict(color='rgb(150, 255, 150)'), name='hand')\n",
    "data_spline = go.Scatter(x=pca_N_spline[:,0], y=pca_N_spline[:,1], marker=dict(color='rgb(200, 50, 200)'), name='spline')\n",
    "fig = go.Figure(data=[data0,data_line,data1,data2,data_hand,data_spline])\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf3f97-ea36-497b-892e-7edbe3cfb421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5831b3-f3f1-4336-81f4-90e2fd25c127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6299ce-b587-4029-a5be-8067d357d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "MRA_pca = MRA_generate(d,nt,1000,sigma,ne,g,replace=1)\n",
    "MRA_pca.generate_default()\n",
    "Cs,Ns = latent(model,MRA_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce11ac-2fa1-4ff3-88d0-52d3e8bdbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(Cs)\n",
    "pca_C = pca.fit_transform(Cs)\n",
    "df = pd.DataFrame(pca_C, columns = ['1st','2nd','3rd'])\n",
    "tem = pd.DataFrame(MRA_pca.states,columns=['state']).astype('object')\n",
    "df = pd.concat([df,tem],axis=1)\n",
    "fig = px.scatter_3d(df, x='1st', y='2nd', z='3rd', color='state')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73668d8-3263-4e16-ae6d-a90db5374be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 0\n",
    "N_reshaped = Ns[MRA_pca.states==state,:].reshape(-1,q) \n",
    "N_shifts = MRA_pca.shifts[MRA_pca.states==state,:].reshape(-1,1)\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(N_reshaped)\n",
    "pca_N = pca.fit_transform(N_reshaped)\n",
    "df = pd.DataFrame(pca_N, columns = ['1st','2nd','3rd'])\n",
    "tem = pd.DataFrame(N_shifts,columns=['shift'])\n",
    "df = pd.concat([df,tem],axis=1)\n",
    "fig = px.scatter_3d(df, x='1st', y='2nd', z='3rd', color='shift')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db248c-9543-4c19-b522-baa4564c9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_C = pca.fit_transform(Cs)\n",
    "center = np.empty((ne,2))\n",
    "fig = plt.figure(figsize=(5,4),dpi=100)\n",
    "for i in range(ne):\n",
    "    center[i,:] = sum(pca_C[MRA_pca.states==i,:])/sum(MRA_pca.states==i)\n",
    "    plt.text(center[i,0],center[i,1],\"state=%d\"%i,fontsize=15)\n",
    "for i in trange(1000):\n",
    "    plt.scatter(pca_C[i,0],pca_C[i,1],color='C%d'%(MRA_pca.states[i]))\n",
    "plt.title('PCA of p-space',fontsize=15)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1364c68-422d-4fe1-8a12-fda6fec4da4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5538bf4-4bda-4b69-ac35-80e3ba493ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
