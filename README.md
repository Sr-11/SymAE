# Question: 
## 6/2
1. If we use sigma=0.1 to train the NN, then use sigma=0.0 to test it, the NN will "learn the noise"?  
2. We are over fitting. g0-g9 is not enough. If input generate(random), output still like g's.  
## 6/5
3. If we only use cos(x)...cos(10x) to train SymAE, can't deal with cos(100x)?
4. Coherent code is translation-invarant
5. How do we know whether a NN is convex wrt all parameters? what if it never reached the global minimun
6. I believe there is no way to catch the high frequency informationï¼Ÿ Like the theta is completely random and our training set contains smooth functions
7. 